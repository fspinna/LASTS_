{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skmultilearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1e2d0812cea1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/francesco/github/LOREM-master/code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlorem\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLOREM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecord2str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneuclidean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultilabel2str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/LOREM-master/code/lore/lorem.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompact_premises\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_decision_trees\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge_decision_trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/LOREM-master/code/lore/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatamanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlorem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/LOREM-master/code/lore/datamanager.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskmultilearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_from_arff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skmultilearn'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('/Users/francesco/github/LOREM-master/code')\n",
    "\n",
    "from lorem import LOREM\n",
    "from util import record2str, neuclidean, multilabel2str\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from datamanager import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 0\n",
    "path = '/Users/francesco/github/LOREM-master/'\n",
    "path_data = path + 'dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, class_name = prepare_compass_dataset(path_data + 'compas-scores-two-years.csv', binary=True)\n",
    "df, feature_names, class_values, numeric_columns, rdf, real_feature_names, features_map = prepare_dataset(\n",
    "    df, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratify = None if isinstance(class_name, list) else df[class_name].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[feature_names].values, df[class_name].values, test_size=0.30,\n",
    "                                                    random_state=random_state, stratify=stratify)\n",
    "\n",
    "stratify = None if isinstance(class_name, list) else rdf[class_name].values\n",
    "_, K, _, _ = train_test_split(rdf[real_feature_names].values, rdf[class_name].values, test_size=0.30,\n",
    "                              random_state=random_state, stratify=stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = RandomForestClassifier(n_estimators=10, random_state=random_state)\n",
    "# bb = SVC(random_state=random_state)\n",
    "# bb = MLPClassifier(random_state=random_state)\n",
    "bb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = { age = 36, priors_count = 0, days_b_screening_arrest = 1, is_recid = 1, is_violent_recid = 0, two_year_recid = 1, length_of_stay = 0, age_cat = 25 - 45, sex = Male, race = Caucasian, c_charge_degree = F }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i2e = 1\n",
    "x = X_test[i2e]\n",
    "\n",
    "print('x = %s' % record2str(x, feature_names, numeric_columns))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_predict(X):\n",
    "    return bb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb(x) = { Medium-Low }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bb_outcome = bb_predict(x.reshape(1, -1))[0]\n",
    "bb_outcome_str = class_values[bb_outcome] if isinstance(class_name, str) else multilabel2str(bb_outcome, class_values)\n",
    "print('bb(x) = { %s }' % bb_outcome_str)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating feature values\n",
      "generating neighborhood - rndgen\n",
      "synthetic neighborhood class counts {'High': 434, 'Medium-Low': 715}\n",
      "learning local decision tree\n",
      "retrieving explanation\n",
      "e = {\n",
      "\tr = { priors_count <= 6.44, priors_count > -0.60, age <= 43.77, age > 32.36, race != African-American } --> { class: Medium-Low }\n",
      "\tc = { { priors_count > 8.43 } --> { class: High }, { age <= 4.85 } --> { class: High }, { age > 43.77 } --> { class: High } }    \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "explainer = LOREM(K, bb_predict, feature_names, class_name, class_values, numeric_columns, features_map,\n",
    "                      neigh_type='rndgen', categorical_use_prob=True,\n",
    "                      continuous_fun_estimation=False, size=1000, ocr=0.1, multi_label=False, one_vs_rest=False,\n",
    "                      random_state=random_state, verbose=True, ngen=10)\n",
    "exp = explainer.explain_instance(x, num_samples=1000, use_weights=True, metric=neuclidean)\n",
    "\n",
    "print('e = {\\n\\tr = %s\\n\\tc = %s    \\n}' % (exp.rstr(), exp.cstr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, class_name = prepare_iris_dataset(path_data + 'iris.csv')\n",
    "df, feature_names, class_values, numeric_columns, rdf, real_feature_names, features_map = prepare_dataset(\n",
    "    df, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratify = None if isinstance(class_name, list) else df[class_name].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[feature_names].values, df[class_name].values, test_size=0.30,\n",
    "                                                    random_state=random_state, stratify=stratify)\n",
    "\n",
    "stratify = None if isinstance(class_name, list) else rdf[class_name].values\n",
    "_, K, _, _ = train_test_split(rdf[real_feature_names].values, rdf[class_name].values, test_size=0.30,\n",
    "                              random_state=random_state, stratify=stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = RandomForestClassifier(n_estimators=10, random_state=random_state)\n",
    "# bb = SVC(random_state=random_state)\n",
    "# bb = MLPClassifier(random_state=random_state)\n",
    "bb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = { sepal length = 6.3, sepal width = 3.4, petal length = 5.6, petal width = 2.4 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i2e = 0\n",
    "x = X_test[i2e]\n",
    "\n",
    "print('x = %s' % record2str(x, feature_names, numeric_columns))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_predict(X):\n",
    "    return bb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb(x) = { Iris-virginica }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bb_outcome = bb_predict(x.reshape(1, -1))[0]\n",
    "bb_outcome_str = class_values[bb_outcome] if isinstance(class_name, str) else multilabel2str(bb_outcome, class_values)\n",
    "print('bb(x) = { %s }' % bb_outcome_str)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating feature values\n",
      "generating neighborhood - rndgen\n",
      "synthetic neighborhood class counts {'Iris-setosa': 190, 'Iris-versicolor': 546, 'Iris-virginica': 313}\n",
      "learning local decision tree\n",
      "retrieving explanation\n",
      "e = {\n",
      "\tr = { petal length > 5.11, petal width > 0.78 } --> { class: Iris-virginica }\n",
      "\tc = { { petal length <= 4.62 } --> { class: Iris-versicolor }, { petal width <= 0.74 } --> { class: Iris-setosa } }    \n",
      "}\n"
     ]
    }
   ],
   "source": [
    "explainer = LOREM(K, bb_predict, feature_names, class_name, class_values, numeric_columns, features_map,\n",
    "                      neigh_type='rndgen', categorical_use_prob=True,\n",
    "                      continuous_fun_estimation=False, size=1000, ocr=0.1, multi_label=False, one_vs_rest=False,\n",
    "                      random_state=random_state, verbose=True, ngen=10)\n",
    "exp = explainer.explain_instance(x, num_samples=1000, use_weights=True, metric=neuclidean)\n",
    "\n",
    "print('e = {\\n\\tr = %s\\n\\tc = %s    \\n}' % (exp.rstr(), exp.cstr()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, class_name = prepare_yeast_dataset(path_data + 'yeast.arff')\n",
    "df, feature_names, class_values, numeric_columns, rdf, real_feature_names, features_map = prepare_dataset(\n",
    "    df, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratify = None if isinstance(class_name, list) else df[class_name].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df[feature_names].values, df[class_name].values, test_size=0.30,\n",
    "                                                    random_state=random_state, stratify=stratify)\n",
    "\n",
    "stratify = None if isinstance(class_name, list) else rdf[class_name].values\n",
    "_, K, _, _ = train_test_split(rdf[real_feature_names].values, rdf[class_name].values, test_size=0.30,\n",
    "                              random_state=random_state, stratify=stratify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb = RandomForestClassifier(n_estimators=10, random_state=random_state)\n",
    "# bb = SVC(random_state=random_state)\n",
    "# bb = MLPClassifier(random_state=random_state)\n",
    "bb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = { Att1 = -0.072579, Att2 = -0.090852, Att3 = -0.158701, Att4 = -0.16486, Att5 = -0.106735, Att6 = -0.102631, Att7 = 0.058959, Att8 = 0.050692, Att9 = 0.147338, Att10 = 0.116292, Att11 = 0.002095, Att12 = 0.001357, Att13 = -0.079275, Att14 = -0.070555, Att15 = -0.050414, Att16 = 0.015119, Att17 = 0.041737, Att18 = 0.108965, Att19 = -0.038776, Att20 = 0.091967, Att21 = 0.031552, Att22 = 0.180726, Att23 = 0.096652, Att24 = 0.041474, Att25 = 0.196346, Att26 = 0.057603, Att27 = 0.107898, Att28 = 0.176917, Att29 = 0.127861, Att30 = 0.062869, Att31 = 0.103735, Att32 = 0.196043, Att33 = 0.001996, Att34 = -0.170185, Att35 = -0.217192, Att36 = 0.005996, Att37 = 0.123599, Att38 = 0.16439, Att39 = 0.012365, Att40 = -0.086124, Att41 = -0.082026, Att42 = -0.014118, Att43 = 0.081171, Att44 = 0.034226, Att45 = -0.046256, Att46 = -0.080571, Att47 = -0.066226, Att48 = 0.052526, Att49 = 0.062243, Att50 = -0.001041, Att51 = -0.057956, Att52 = 0.054652, Att53 = 0.130336, Att54 = 0.082482, Att55 = -0.050028, Att56 = 0.121285, Att57 = -0.011101, Att58 = -0.120219, Att59 = 0.065582, Att60 = 0.022895, Att61 = -0.095509, Att62 = 0.017891, Att63 = 0.123906, Att64 = 0.078104, Att65 = -0.09574, Att66 = -0.209948, Att67 = -0.054137, Att68 = -0.007888, Att69 = 0.05983, Att70 = -0.125898, Att71 = -0.078233, Att72 = 0.002804, Att73 = -0.015014, Att74 = -0.060568, Att75 = -0.024619, Att76 = 0.044271, Att77 = -0.028746, Att78 = -0.121112, Att79 = -0.036928, Att80 = 0.021176, Att81 = -0.018592, Att82 = 0.108101, Att83 = -0.141879, Att84 = 0.074193, Att85 = -0.073465, Att86 = -0.052507, Att87 = -0.028271, Att88 = 0.081541, Att89 = -0.056438, Att90 = -0.067583, Att91 = -0.063439, Att92 = 0.060603, Att93 = 0.332538, Att94 = 0.060056, Att95 = 0.163619, Att96 = 0.018197, Att97 = -0.036094, Att98 = -0.14392, Att99 = -0.14187, Att100 = 0.094205, Att101 = -0.036016, Att102 = -0.004184, Att103 = -0.091306 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i2e = 0\n",
    "x = X_test[i2e]\n",
    "\n",
    "print('x = %s' % record2str(x, feature_names, numeric_columns))\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_predict(X):\n",
    "    return bb.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bb(x) = { Class7, Class8 }\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bb_outcome = bb_predict(x.reshape(1, -1))[0]\n",
    "bb_outcome_str = class_values[bb_outcome] if isinstance(class_name, str) else multilabel2str(bb_outcome, class_values)\n",
    "print('bb(x) = { %s }' % bb_outcome_str)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating neighborhood - closest\n",
      "calculating feature values\n",
      "synthetic neighborhood class counts {'Class1': 85.0, 'Class10': 275.0, 'Class11': 235.0, 'Class12': 79.0, 'Class13': 24.0, 'Class14': 21.0, 'Class2': 5.0, 'Class3': 5.0, 'Class4': 0.0, 'Class5': 0.0, 'Class6': 3.0, 'Class7': 846.0, 'Class8': 831.0, 'Class9': 0.0}\n",
      "learning local decision tree\n",
      "retrieving explanation\n",
      "e = {\n",
      "\tr = { Att88 > -0.03, Att37 <= 0.20, Att72 <= 0.02, Att6 <= 0.10, Att24 <= 0.12, Att32 <= 0.29, Att59 > -0.21, Att93 <= 0.43, Att17 <= 0.17, Att102 > -0.01, Att99 <= 0.02, Att56 <= 0.25, Att9 <= 0.22, Att92 > -0.26, Att25 <= 0.22, Att25 > -0.20, Att27 <= 0.22, Att90 > -0.18, Att94 > -0.12, Att30 > -0.20, Att74 <= 0.17, Att85 <= 0.19, Att64 <= 0.26, Att49 > -0.27, Att101 <= 0.06, Att33 > -0.11, Att70 <= 0.18, Att8 <= 0.08, Att5 > -0.26, Att51 > -0.18, Att34 > -0.21, Att15 > -0.15 } --> { Class7, Class8 }\n",
      "\tc = { { Att27 > 0.22 } --> { Class13, Class14, Class7, Class8 }, { Att70 > 0.18 } --> { Class10, Class7, Class8 }, { Att85 > 0.19 } --> { Class13, Class14, Class7, Class8 }, { Att94 <= -0.14 } --> { Class7 }, { Att24 > 0.12 } --> { Class10, Class11, Class7, Class8 }, { Att6 > 0.10 } --> { Class1, Class10 }, { Att8 > 0.08 } --> { Class11, Class7, Class8 }, { Att59 <= -0.21 } --> { Class1, Class10, Class7, Class8 }, { Att5 <= -0.26 } --> { Class11, Class7, Class8 }, { Att99 > 0.02 } --> { Class11, Class7, Class8 }, { Att56 > 0.25 } --> { Class10 }, { Att72 > 0.02 } --> { Class11, Class7, Class8 }, { Att33 <= -0.11 } --> { Class1, Class7, Class8 }, { Att92 <= -0.26 } --> { Class10, Class7, Class8 }, { Att15 <= -0.15 } --> { Class1, Class7, Class8 }, { Att37 > 0.20 } --> { Class10, Class7, Class8 }, { Att90 <= -0.18 } --> { Class11, Class12, Class7, Class8 }, { Att49 <= -0.27 } --> { Class10, Class11, Class7, Class8 }, { Att9 > 0.22 } --> { Class10, Class13, Class14, Class7, Class8 }, { Att34 <= -0.21 } --> { Class3, Class7, Class8 }, { Att64 > 0.26 } --> { Class10, Class7, Class8 }, { Att93 > 0.43 } --> { Class11, Class12 }, { Att32 > 0.29 } --> { Class10 }, { Att17 > 0.17 } --> { Class10, Class7, Class8 }, { Att51 <= -0.18 } --> { Class10, Class7, Class8 }, { Att30 <= -0.20 } --> { Class14, Class2, Class7, Class8 }, { Att94 <= -0.12 } --> { Class10, Class11, Class7, Class8 }, { Att25 > 0.22 } --> { Class11, Class12, Class7, Class8 }, { Att74 > 0.17 } --> { Class14, Class2, Class7, Class8 }, { Att25 <= -0.20 } --> { Class13, Class14, Class7, Class8 }, { Att101 > 0.06 } --> { Class11, Class7, Class8 } }    \n",
      "}\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.] 1.0\n"
     ]
    }
   ],
   "source": [
    "explainer = LOREM(K, bb_predict, feature_names, class_name, class_values, numeric_columns, features_map,\n",
    "                  neigh_type='closest', categorical_use_prob=True,\n",
    "                  continuous_fun_estimation=False, size=1000, ocr=0.1, multi_label=True, one_vs_rest=False,\n",
    "                  random_state=random_state, verbose=True, Kc=X_test, core_neigh_type='unified')\n",
    "exp = explainer.explain_instance(x, num_samples=1000, use_weights=True, metric=neuclidean)\n",
    "\n",
    "print('e = {\\n\\tr = %s\\n\\tc = %s    \\n}' % (exp.rstr(), exp.cstr()))\n",
    "# for crule in exp.crules:\n",
    "#     print(crule)\n",
    "print(exp.bb_pred, exp.dt_pred, exp.fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
