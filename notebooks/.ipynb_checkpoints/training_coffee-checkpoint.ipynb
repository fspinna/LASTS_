{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from datasets import build_coffee\n",
    "from blackboxes import build_resnet\n",
    "import numpy as np\n",
    "import time\n",
    "import keras\n",
    "from blackbox_wrapper import BlackboxWrapper\n",
    "from variational_autoencoder import build_vae, plot_history\n",
    "from utils import reconstruction_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET INFO:\n",
      "X SHAPE:  (28, 286, 1)\n",
      "y SHAPE:  (28,)\n",
      "\n",
      "CLASSES BALANCE\n",
      "0 :  0.5\n",
      "1 :  0.5\n",
      "\n",
      "SHAPES:\n",
      "BLACKBOX TRAINING SET:  (28, 286, 1)\n",
      "BLACKBOX VALIDATION SET:  (0,)\n",
      "BLACKBOX TEST SET:  (28, 286, 1)\n",
      "EXPLANATION TRAINING SET:  (28, 286, 1)\n",
      "EXPLANATION VALIDATION SET:  (0,)\n",
      "EXPLANATION TEST SET:  (28, 286, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/francesco/github/LASTS/datasets.py:651: UserWarning: The validation sets are empty, use cross-validation to evaluate models\n",
      "  warnings.warn(\"The validation sets are empty, use cross-validation to evaluate models\")\n",
      "/Users/francesco/github/LASTS/datasets.py:652: UserWarning: Blackbox and Explanation sets are the same\n",
      "  warnings.warn(\"Blackbox and Explanation sets are the same\")\n"
     ]
    }
   ],
   "source": [
    "# IMPORT DATASET\n",
    "random_state = 0\n",
    "dataset_name = \"coffee\"\n",
    "dataset_dir = \"/trained_models/\" + dataset_name + \"/\"\n",
    "\n",
    "(X_train, y_train, X_val, y_val, \n",
    " X_test, y_test, X_exp_train, y_exp_train, \n",
    " X_exp_val, y_exp_val, X_exp_test, y_exp_test) = build_coffee(random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1:]\n",
    "n_timesteps = input_shape[0]\n",
    "n_classes = len(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in np.unique(y_train):\n",
    "    plt.figure(figsize=(20,3))\n",
    "    by_label = y_train == i\n",
    "    plt.plot(X_train[by_label][:,:,0].T, c=\"gray\", alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"#metriche usate nella grid search\n",
    "scoring = {'MSE':make_scorer(mean_squared_error, greater_is_better=False), 'Accuracy': make_scorer(accuracy_score)}\n",
    "\n",
    "#iperparametri\n",
    "n_neighbors = list(range(1, 10))\n",
    "metric = [\"euclidean\", \"manhattan\"]\n",
    "#weights = ['uniform', 'distance']\n",
    "weights = ['distance']\n",
    "param_grid = dict(n_neighbors = n_neighbors, weights = weights, metric = metric)\n",
    "\n",
    "#Definition of algorithm and GridSearch\n",
    "knn = KNeighborsClassifier(algorithm='auto')\n",
    "cv = StratifiedKFold(random_state=random_state, n_splits=3)\n",
    "grid = GridSearchCV(knn, param_grid = param_grid, cv = cv, scoring = scoring, n_jobs=-1, \n",
    "                    return_train_score=True, refit='MSE', verbose=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 143 ms, sys: 59.8 ms, total: 203 ms\n",
      "Wall time: 1.83 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:    1.8s finished\n",
      "/Users/francesco/anaconda3/envs/tesi/lib/python3.6/site-packages/sklearn/model_selection/_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "grid.fit(X_train[:,:,0], y_train)\n",
    "results = grid.cv_results_\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'euclidean', 'n_neighbors': 1, 'weights': 'distance'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(grid.best_params_)\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.at[grid.best_index_, 'mean_test_Accuracy']\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"knn = KNeighborsClassifier(**grid.best_params_)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='distance')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"knn.fit(X_train.reshape(X_train.shape[:2]), y_train)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['coffee_knn.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"dump(knn, \"coffee_knn.joblib\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = load(parentdir + dataset_dir + dataset_name + \"_knn.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test[:,:,0], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox = BlackboxWrapper(knn, 2, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "resnet = build_resnet(n_timesteps, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = parentdir + dataset_dir + \"weights/blackboxes/\" + time.strftime(\"%Y%m%d_%H%M%S\") + \"/\"\n",
    "os.makedirs(save_folder)\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "file_path = save_folder + \"blackbox_resnet_\" + \"_best_weights_+{loss:.2f}_.hdf5\" \n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, \n",
    "                                                   monitor='loss', \n",
    "                                                   save_weights_only = True, \n",
    "                                                   verbose = 1,\n",
    "                                                   save_best_only=True)\n",
    "\n",
    "\n",
    "callbacks = [reduce_lr, model_checkpoint]\n",
    "\n",
    "batch_size = 16\n",
    "mini_batch_size = int(min(X_train.shape[0]/10, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/francesco/anaconda3/envs/lasts_01/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 31s 1s/step - loss: 0.8323 - acc: 0.4286\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.83228, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.83_.hdf5\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 3s 116ms/step - loss: 0.3962 - acc: 0.8929\n",
      "\n",
      "Epoch 00002: loss improved from 0.83228 to 0.39615, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.40_.hdf5\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 5s 169ms/step - loss: 0.3949 - acc: 0.7857\n",
      "\n",
      "Epoch 00003: loss improved from 0.39615 to 0.39490, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.39_.hdf5\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 4s 140ms/step - loss: 0.5236 - acc: 0.7500\n",
      "\n",
      "Epoch 00004: loss did not improve from 0.39490\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 3s 123ms/step - loss: 0.2497 - acc: 0.8929\n",
      "\n",
      "Epoch 00005: loss improved from 0.39490 to 0.24968, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.25_.hdf5\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 4s 143ms/step - loss: 0.4413 - acc: 0.7857\n",
      "\n",
      "Epoch 00006: loss did not improve from 0.24968\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 4s 130ms/step - loss: 0.3888 - acc: 0.7500\n",
      "\n",
      "Epoch 00007: loss did not improve from 0.24968\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 4s 130ms/step - loss: 0.3955 - acc: 0.7857\n",
      "\n",
      "Epoch 00008: loss did not improve from 0.24968\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.3583 - acc: 0.8571\n",
      "\n",
      "Epoch 00009: loss did not improve from 0.24968\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 0.3832 - acc: 0.8214\n",
      "\n",
      "Epoch 00010: loss did not improve from 0.24968\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 4s 127ms/step - loss: 0.4132 - acc: 0.7500\n",
      "\n",
      "Epoch 00011: loss did not improve from 0.24968\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 3s 106ms/step - loss: 0.3222 - acc: 0.8571\n",
      "\n",
      "Epoch 00012: loss did not improve from 0.24968\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 3s 115ms/step - loss: 0.6900 - acc: 0.7143\n",
      "\n",
      "Epoch 00013: loss did not improve from 0.24968\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 3s 114ms/step - loss: 0.4368 - acc: 0.7143\n",
      "\n",
      "Epoch 00014: loss did not improve from 0.24968\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.4341 - acc: 0.7500\n",
      "\n",
      "Epoch 00015: loss did not improve from 0.24968\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 3s 107ms/step - loss: 0.2568 - acc: 0.9286\n",
      "\n",
      "Epoch 00016: loss did not improve from 0.24968\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 3s 112ms/step - loss: 0.3922 - acc: 0.8571\n",
      "\n",
      "Epoch 00017: loss did not improve from 0.24968\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.3058 - acc: 0.9286\n",
      "\n",
      "Epoch 00018: loss did not improve from 0.24968\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 3s 111ms/step - loss: 0.3092 - acc: 0.8929\n",
      "\n",
      "Epoch 00019: loss did not improve from 0.24968\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.1784 - acc: 0.9643\n",
      "\n",
      "Epoch 00020: loss improved from 0.24968 to 0.17843, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.18_.hdf5\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 3s 115ms/step - loss: 0.1021 - acc: 1.0000\n",
      "\n",
      "Epoch 00021: loss improved from 0.17843 to 0.10209, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.10_.hdf5\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.1157 - acc: 1.0000\n",
      "\n",
      "Epoch 00022: loss did not improve from 0.10209\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.0681 - acc: 1.0000\n",
      "\n",
      "Epoch 00023: loss improved from 0.10209 to 0.06808, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.07_.hdf5\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 3s 103ms/step - loss: 0.1921 - acc: 0.9286\n",
      "\n",
      "Epoch 00024: loss did not improve from 0.06808\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 0.1493 - acc: 1.0000\n",
      "\n",
      "Epoch 00025: loss did not improve from 0.06808\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.1368 - acc: 0.9286\n",
      "\n",
      "Epoch 00026: loss did not improve from 0.06808\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 3s 109ms/step - loss: 0.3256 - acc: 0.8929\n",
      "\n",
      "Epoch 00027: loss did not improve from 0.06808\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 3s 120ms/step - loss: 0.3176 - acc: 0.8929\n",
      "\n",
      "Epoch 00028: loss did not improve from 0.06808\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.1595 - acc: 0.9643\n",
      "\n",
      "Epoch 00029: loss did not improve from 0.06808\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 3s 113ms/step - loss: 0.0452 - acc: 1.0000\n",
      "\n",
      "Epoch 00030: loss improved from 0.06808 to 0.04521, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.05_.hdf5\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.0313 - acc: 1.0000\n",
      "\n",
      "Epoch 00031: loss improved from 0.04521 to 0.03128, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.03_.hdf5\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 3s 108ms/step - loss: 0.0409 - acc: 1.0000\n",
      "\n",
      "Epoch 00032: loss did not improve from 0.03128\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 3s 102ms/step - loss: 0.0267 - acc: 1.0000\n",
      "\n",
      "Epoch 00033: loss improved from 0.03128 to 0.02670, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.03_.hdf5\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.0200 - acc: 1.0000\n",
      "\n",
      "Epoch 00034: loss improved from 0.02670 to 0.02003, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.02_.hdf5\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 3s 105ms/step - loss: 0.0112 - acc: 1.0000\n",
      "\n",
      "Epoch 00035: loss improved from 0.02003 to 0.01120, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.01_.hdf5\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0156 - acc: 1.0000\n",
      "\n",
      "Epoch 00036: loss did not improve from 0.01120\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 3s 102ms/step - loss: 0.0140 - acc: 1.0000\n",
      "\n",
      "Epoch 00037: loss did not improve from 0.01120\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 3s 98ms/step - loss: 0.0098 - acc: 1.0000\n",
      "\n",
      "Epoch 00038: loss improved from 0.01120 to 0.00980, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.01_.hdf5\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 3s 104ms/step - loss: 0.0078 - acc: 1.0000\n",
      "\n",
      "Epoch 00039: loss improved from 0.00980 to 0.00775, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.01_.hdf5\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0059 - acc: 1.0000\n",
      "\n",
      "Epoch 00040: loss improved from 0.00775 to 0.00593, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.01_.hdf5\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 3s 99ms/step - loss: 0.0091 - acc: 1.0000\n",
      "\n",
      "Epoch 00041: loss did not improve from 0.00593\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 3s 93ms/step - loss: 0.0109 - acc: 1.0000\n",
      "\n",
      "Epoch 00042: loss did not improve from 0.00593\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0059 - acc: 1.0000\n",
      "\n",
      "Epoch 00043: loss did not improve from 0.00593\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0058 - acc: 1.0000\n",
      "\n",
      "Epoch 00044: loss improved from 0.00593 to 0.00578, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.01_.hdf5\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 3s 97ms/step - loss: 0.0036 - acc: 1.0000\n",
      "\n",
      "Epoch 00045: loss improved from 0.00578 to 0.00357, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.00_.hdf5\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 3s 104ms/step - loss: 0.0048 - acc: 1.0000\n",
      "\n",
      "Epoch 00046: loss did not improve from 0.00357\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0040 - acc: 1.0000\n",
      "\n",
      "Epoch 00047: loss did not improve from 0.00357\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 3s 101ms/step - loss: 0.0026 - acc: 1.0000\n",
      "\n",
      "Epoch 00048: loss improved from 0.00357 to 0.00260, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/blackboxes/20210211_162943/blackbox_resnet__best_weights_+0.00_.hdf5\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 3s 94ms/step - loss: 0.0032 - acc: 1.0000\n",
      "\n",
      "Epoch 00049: loss did not improve from 0.00260\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 3s 95ms/step - loss: 0.0035 - acc: 1.0000\n",
      "\n",
      "Epoch 00050: loss did not improve from 0.00260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a461078d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=50, \n",
    "    batch_size=mini_batch_size, \n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.load_weights(save_folder + \"blackbox_resnet__best_weights_+0.00_.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "28/28 [==============================] - 5s 192ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.022571155801415443, 1.0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.save(\"coffee_resnet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_autoencoder import rec_loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "autoencoder_kwargs = {\n",
    "    \"filters\": [8, 8, 8, 8, 8, 8, 8, 8],\n",
    "    \"kernel_size\": [3, 3, 3, 3, 3, 3, 3, 3],\n",
    "    \"padding\": [\"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\", \"same\"],\n",
    "    \"activation\": [\"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\", \"relu\"],\n",
    "    \"pooling\": [1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    \"n_layers\": 8,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"n_layers_residual\": None,\n",
    "    \"batch_normalization\": False,\n",
    "    \"loss\": rec_loss_sum\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           (None, 286, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_91 (Conv1D)              (None, 286, 8)       32          input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 286, 8)       32          conv1d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 286, 8)       0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 286, 8)       0           activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_92 (Conv1D)              (None, 286, 8)       200         max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 286, 8)       32          conv1d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 286, 8)       0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 286, 8)       0           activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_93 (Conv1D)              (None, 286, 8)       200         max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 286, 8)       32          conv1d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 286, 8)       0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 286, 8)       0           activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_94 (Conv1D)              (None, 286, 8)       200         max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 286, 8)       32          conv1d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 286, 8)       0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 286, 8)       0           activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_95 (Conv1D)              (None, 286, 8)       200         max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 286, 8)       32          conv1d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 286, 8)       0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 286, 8)       0           activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_96 (Conv1D)              (None, 286, 8)       200         max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 286, 8)       32          conv1d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 286, 8)       0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 286, 8)       0           activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_97 (Conv1D)              (None, 286, 8)       200         max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 286, 8)       32          conv1d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 286, 8)       0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 286, 8)       0           activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_98 (Conv1D)              (None, 286, 8)       200         max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 286, 8)       32          conv1d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 286, 8)       0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 286, 8)       0           activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_99 (Conv1D)              (None, 286, 1)       9           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 286)          0           conv1d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 2)            574         flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 2)            574         flatten_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "kl_divergence_layer_6 (KLDiverg [(None, 2), (None, 2 0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2)            0           kl_divergence_layer_6[0][1]      \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 2)            0           lambda_6[0][0]                   \n",
      "                                                                 input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 2)            0           kl_divergence_layer_6[0][0]      \n",
      "                                                                 multiply_6[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,845\n",
      "Trainable params: 2,717\n",
      "Non-trainable params: 128\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"Decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "z_sampling (InputLayer)      (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 286)               858       \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 286, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "batch_normalization_89 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_41 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_90 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_42 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_91 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_43 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_44 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_45 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_46 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_47 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 286, 8)            200       \n",
      "_________________________________________________________________\n",
      "batch_normalization_96 (Batc (None, 286, 8)            32        \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "up_sampling1d_48 (UpSampling (None, 286, 8)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 286, 1)            9         \n",
      "=================================================================\n",
      "Total params: 2,555\n",
      "Trainable params: 2,427\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           (None, 286, 1)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder (Model)                 (None, 2)            2845        input_23[0][0]                   \n",
      "                                                                 input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (Model)                 (None, 286, 1)       2555        Encoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,400\n",
      "Trainable params: 5,144\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder, decoder, autoencoder = build_vae(input_shape, latent_dim, autoencoder_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = parentdir + dataset_dir + \"weights/autoencoders/\" + time.strftime(\"%Y%m%d_%H%M%S\") + \"/\"\n",
    "os.makedirs(save_folder)\n",
    "\n",
    "autoencoder_kwargs.pop(\"loss\", None)\n",
    "model_kwargs = {\"input_shape\": input_shape, \"latent_dim\": latent_dim, \"autoencoder_kwargs\": autoencoder_kwargs}\n",
    "dump(model_kwargs, save_folder + \"model_kwargs.joblib\")\n",
    "\n",
    "\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='mean_squared_error', factor=0.5, patience=200, min_lr=0.0001)\n",
    "file_path = save_folder + \"vae\" + \"_best_weights.hdf5\" \n",
    "\n",
    "model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, \n",
    "                                                   monitor='mean_squared_error', \n",
    "                                                   save_weights_only = True, \n",
    "                                                   verbose = 1,\n",
    "                                                   save_best_only=True)\n",
    "\n",
    "callbacks = [reduce_lr, model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "28/28 [==============================] - 54s 2s/step - loss: 330.2717 - mean_squared_error: 1.1482\n",
      "\n",
      "Epoch 00001: mean_squared_error improved from inf to 1.14820, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 2/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 320.4287 - mean_squared_error: 1.1112\n",
      "\n",
      "Epoch 00002: mean_squared_error improved from 1.14820 to 1.11118, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 3/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 315.4597 - mean_squared_error: 1.0926\n",
      "\n",
      "Epoch 00003: mean_squared_error improved from 1.11118 to 1.09262, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 4/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 306.5969 - mean_squared_error: 1.0607\n",
      "\n",
      "Epoch 00004: mean_squared_error improved from 1.09262 to 1.06068, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 5/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 303.7173 - mean_squared_error: 1.0485\n",
      "\n",
      "Epoch 00005: mean_squared_error improved from 1.06068 to 1.04852, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 6/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 295.3581 - mean_squared_error: 1.0178\n",
      "\n",
      "Epoch 00006: mean_squared_error improved from 1.04852 to 1.01776, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 7/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 290.6076 - mean_squared_error: 1.0001\n",
      "\n",
      "Epoch 00007: mean_squared_error improved from 1.01776 to 1.00014, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 8/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 277.5784 - mean_squared_error: 0.9543\n",
      "\n",
      "Epoch 00008: mean_squared_error improved from 1.00014 to 0.95425, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 9/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 272.7523 - mean_squared_error: 0.9370\n",
      "\n",
      "Epoch 00009: mean_squared_error improved from 0.95425 to 0.93696, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 10/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 264.2520 - mean_squared_error: 0.9066\n",
      "\n",
      "Epoch 00010: mean_squared_error improved from 0.93696 to 0.90665, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 11/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 258.3338 - mean_squared_error: 0.8848\n",
      "\n",
      "Epoch 00011: mean_squared_error improved from 0.90665 to 0.88478, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 12/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 255.7803 - mean_squared_error: 0.8736\n",
      "\n",
      "Epoch 00012: mean_squared_error improved from 0.88478 to 0.87364, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 13/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 252.2813 - mean_squared_error: 0.8589\n",
      "\n",
      "Epoch 00013: mean_squared_error improved from 0.87364 to 0.85890, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 14/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 231.9249 - mean_squared_error: 0.7848\n",
      "\n",
      "Epoch 00014: mean_squared_error improved from 0.85890 to 0.78485, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 15/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 225.1759 - mean_squared_error: 0.7584\n",
      "\n",
      "Epoch 00015: mean_squared_error improved from 0.78485 to 0.75840, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 16/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 220.1947 - mean_squared_error: 0.7379\n",
      "\n",
      "Epoch 00016: mean_squared_error improved from 0.75840 to 0.73788, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 17/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 208.1567 - mean_squared_error: 0.6944\n",
      "\n",
      "Epoch 00017: mean_squared_error improved from 0.73788 to 0.69443, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 18/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 201.9928 - mean_squared_error: 0.6716\n",
      "\n",
      "Epoch 00018: mean_squared_error improved from 0.69443 to 0.67164, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 19/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 194.7377 - mean_squared_error: 0.6453\n",
      "\n",
      "Epoch 00019: mean_squared_error improved from 0.67164 to 0.64527, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 20/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 185.9322 - mean_squared_error: 0.6133\n",
      "\n",
      "Epoch 00020: mean_squared_error improved from 0.64527 to 0.61329, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 21/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 181.5638 - mean_squared_error: 0.5970\n",
      "\n",
      "Epoch 00021: mean_squared_error improved from 0.61329 to 0.59696, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 22/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 171.1708 - mean_squared_error: 0.5590\n",
      "\n",
      "Epoch 00022: mean_squared_error improved from 0.59696 to 0.55901, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 23/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 166.4728 - mean_squared_error: 0.5413\n",
      "\n",
      "Epoch 00023: mean_squared_error improved from 0.55901 to 0.54131, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 24/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 163.2667 - mean_squared_error: 0.5290\n",
      "\n",
      "Epoch 00024: mean_squared_error improved from 0.54131 to 0.52898, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 25/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 155.5129 - mean_squared_error: 0.5007\n",
      "\n",
      "Epoch 00025: mean_squared_error improved from 0.52898 to 0.50073, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 26/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 148.8711 - mean_squared_error: 0.4768\n",
      "\n",
      "Epoch 00026: mean_squared_error improved from 0.50073 to 0.47677, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 27/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 143.0849 - mean_squared_error: 0.4562\n",
      "\n",
      "Epoch 00027: mean_squared_error improved from 0.47677 to 0.45618, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 28/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 136.9726 - mean_squared_error: 0.4346\n",
      "\n",
      "Epoch 00028: mean_squared_error improved from 0.45618 to 0.43459, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 29/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 131.7025 - mean_squared_error: 0.4161\n",
      "\n",
      "Epoch 00029: mean_squared_error improved from 0.43459 to 0.41607, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 30/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 126.8543 - mean_squared_error: 0.3995\n",
      "\n",
      "Epoch 00030: mean_squared_error improved from 0.41607 to 0.39950, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 31/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 121.8385 - mean_squared_error: 0.3827\n",
      "\n",
      "Epoch 00031: mean_squared_error improved from 0.39950 to 0.38271, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 32/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 117.6678 - mean_squared_error: 0.3691\n",
      "\n",
      "Epoch 00032: mean_squared_error improved from 0.38271 to 0.36911, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 33/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 111.7471 - mean_squared_error: 0.3493\n",
      "\n",
      "Epoch 00033: mean_squared_error improved from 0.36911 to 0.34932, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 34/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 108.8282 - mean_squared_error: 0.3401\n",
      "\n",
      "Epoch 00034: mean_squared_error improved from 0.34932 to 0.34010, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 35/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 103.3228 - mean_squared_error: 0.3216\n",
      "\n",
      "Epoch 00035: mean_squared_error improved from 0.34010 to 0.32158, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 36/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 100.3663 - mean_squared_error: 0.3121\n",
      "\n",
      "Epoch 00036: mean_squared_error improved from 0.32158 to 0.31206, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 37/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 96.1280 - mean_squared_error: 0.2980\n",
      "\n",
      "Epoch 00037: mean_squared_error improved from 0.31206 to 0.29799, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 38/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 90.8689 - mean_squared_error: 0.2804\n",
      "\n",
      "Epoch 00038: mean_squared_error improved from 0.29799 to 0.28043, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 39/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 88.7665 - mean_squared_error: 0.2741\n",
      "\n",
      "Epoch 00039: mean_squared_error improved from 0.28043 to 0.27406, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 40/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 83.9728 - mean_squared_error: 0.2581\n",
      "\n",
      "Epoch 00040: mean_squared_error improved from 0.27406 to 0.25811, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 41/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 81.8124 - mean_squared_error: 0.2516\n",
      "\n",
      "Epoch 00041: mean_squared_error improved from 0.25811 to 0.25158, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 42/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 77.8426 - mean_squared_error: 0.2389\n",
      "\n",
      "Epoch 00042: mean_squared_error improved from 0.25158 to 0.23891, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 43/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 75.0045 - mean_squared_error: 0.2301\n",
      "\n",
      "Epoch 00043: mean_squared_error improved from 0.23891 to 0.23015, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 44/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 72.5842 - mean_squared_error: 0.2227\n",
      "\n",
      "Epoch 00044: mean_squared_error improved from 0.23015 to 0.22274, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 45/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 67.7052 - mean_squared_error: 0.2065\n",
      "\n",
      "Epoch 00045: mean_squared_error improved from 0.22274 to 0.20652, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 46/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 65.2785 - mean_squared_error: 0.1990\n",
      "\n",
      "Epoch 00046: mean_squared_error improved from 0.20652 to 0.19899, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 47/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 62.0155 - mean_squared_error: 0.1885\n",
      "\n",
      "Epoch 00047: mean_squared_error improved from 0.19899 to 0.18850, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 48/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 60.1725 - mean_squared_error: 0.1829\n",
      "\n",
      "Epoch 00048: mean_squared_error improved from 0.18850 to 0.18290, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 49/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 57.2689 - mean_squared_error: 0.1733\n",
      "\n",
      "Epoch 00049: mean_squared_error improved from 0.18290 to 0.17329, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 50/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 54.0943 - mean_squared_error: 0.1628\n",
      "\n",
      "Epoch 00050: mean_squared_error improved from 0.17329 to 0.16282, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 51/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 52.1531 - mean_squared_error: 0.1566\n",
      "\n",
      "Epoch 00051: mean_squared_error improved from 0.16282 to 0.15664, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 52/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 49.6121 - mean_squared_error: 0.1481\n",
      "\n",
      "Epoch 00052: mean_squared_error improved from 0.15664 to 0.14810, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 53/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 48.7783 - mean_squared_error: 0.1452\n",
      "\n",
      "Epoch 00053: mean_squared_error improved from 0.14810 to 0.14517, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 54/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 46.4197 - mean_squared_error: 0.1370\n",
      "\n",
      "Epoch 00054: mean_squared_error improved from 0.14517 to 0.13701, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 55/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 12ms/step - loss: 42.4051 - mean_squared_error: 0.1225\n",
      "\n",
      "Epoch 00055: mean_squared_error improved from 0.13701 to 0.12247, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 56/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 41.7313 - mean_squared_error: 0.1197\n",
      "\n",
      "Epoch 00056: mean_squared_error improved from 0.12247 to 0.11966, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 57/2000\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 39.1712 - mean_squared_error: 0.1105\n",
      "\n",
      "Epoch 00057: mean_squared_error improved from 0.11966 to 0.11048, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 58/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 36.9202 - mean_squared_error: 0.1024\n",
      "\n",
      "Epoch 00058: mean_squared_error improved from 0.11048 to 0.10243, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 59/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 35.4033 - mean_squared_error: 0.0971\n",
      "\n",
      "Epoch 00059: mean_squared_error improved from 0.10243 to 0.09712, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 60/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 34.7200 - mean_squared_error: 0.0948\n",
      "\n",
      "Epoch 00060: mean_squared_error improved from 0.09712 to 0.09481, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 61/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 33.1245 - mean_squared_error: 0.0892\n",
      "\n",
      "Epoch 00061: mean_squared_error improved from 0.09481 to 0.08921, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 62/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 31.3660 - mean_squared_error: 0.0833\n",
      "\n",
      "Epoch 00062: mean_squared_error improved from 0.08921 to 0.08332, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 63/2000\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 30.1368 - mean_squared_error: 0.0793\n",
      "\n",
      "Epoch 00063: mean_squared_error improved from 0.08332 to 0.07930, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 64/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 29.1988 - mean_squared_error: 0.0763\n",
      "\n",
      "Epoch 00064: mean_squared_error improved from 0.07930 to 0.07627, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 65/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 27.6696 - mean_squared_error: 0.0713\n",
      "\n",
      "Epoch 00065: mean_squared_error improved from 0.07627 to 0.07133, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 66/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 27.2437 - mean_squared_error: 0.0703\n",
      "\n",
      "Epoch 00066: mean_squared_error improved from 0.07133 to 0.07029, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 67/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 26.4659 - mean_squared_error: 0.0678\n",
      "\n",
      "Epoch 00067: mean_squared_error improved from 0.07029 to 0.06784, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 68/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 24.8676 - mean_squared_error: 0.0623\n",
      "\n",
      "Epoch 00068: mean_squared_error improved from 0.06784 to 0.06232, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 69/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 25.5617 - mean_squared_error: 0.0649\n",
      "\n",
      "Epoch 00069: mean_squared_error did not improve from 0.06232\n",
      "Epoch 70/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 24.2426 - mean_squared_error: 0.0602\n",
      "\n",
      "Epoch 00070: mean_squared_error improved from 0.06232 to 0.06023, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 71/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 23.6885 - mean_squared_error: 0.0583\n",
      "\n",
      "Epoch 00071: mean_squared_error improved from 0.06023 to 0.05832, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 72/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 22.2043 - mean_squared_error: 0.0531\n",
      "\n",
      "Epoch 00072: mean_squared_error improved from 0.05832 to 0.05313, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 73/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 23.3807 - mean_squared_error: 0.0573\n",
      "\n",
      "Epoch 00073: mean_squared_error did not improve from 0.05313\n",
      "Epoch 74/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 21.8654 - mean_squared_error: 0.0520\n",
      "\n",
      "Epoch 00074: mean_squared_error improved from 0.05313 to 0.05204, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 75/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 21.1669 - mean_squared_error: 0.0496\n",
      "\n",
      "Epoch 00075: mean_squared_error improved from 0.05204 to 0.04958, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 76/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 20.9227 - mean_squared_error: 0.0486\n",
      "\n",
      "Epoch 00076: mean_squared_error improved from 0.04958 to 0.04862, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 77/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 21.2558 - mean_squared_error: 0.0498\n",
      "\n",
      "Epoch 00077: mean_squared_error did not improve from 0.04862\n",
      "Epoch 78/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 22.3334 - mean_squared_error: 0.0535\n",
      "\n",
      "Epoch 00078: mean_squared_error did not improve from 0.04862\n",
      "Epoch 79/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 18.8034 - mean_squared_error: 0.0407\n",
      "\n",
      "Epoch 00079: mean_squared_error improved from 0.04862 to 0.04072, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 80/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 19.1203 - mean_squared_error: 0.0416\n",
      "\n",
      "Epoch 00080: mean_squared_error did not improve from 0.04072\n",
      "Epoch 81/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 18.5378 - mean_squared_error: 0.0395\n",
      "\n",
      "Epoch 00081: mean_squared_error improved from 0.04072 to 0.03948, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 82/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 18.8418 - mean_squared_error: 0.0406\n",
      "\n",
      "Epoch 00082: mean_squared_error did not improve from 0.03948\n",
      "Epoch 83/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 17.9354 - mean_squared_error: 0.0375\n",
      "\n",
      "Epoch 00083: mean_squared_error improved from 0.03948 to 0.03746, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 84/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 17.0901 - mean_squared_error: 0.0346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00084: mean_squared_error improved from 0.03746 to 0.03458, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 85/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 17.2035 - mean_squared_error: 0.0352\n",
      "\n",
      "Epoch 00085: mean_squared_error did not improve from 0.03458\n",
      "Epoch 86/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 16.3118 - mean_squared_error: 0.0324\n",
      "\n",
      "Epoch 00086: mean_squared_error improved from 0.03458 to 0.03236, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 87/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 17.3333 - mean_squared_error: 0.0362\n",
      "\n",
      "Epoch 00087: mean_squared_error did not improve from 0.03236\n",
      "Epoch 88/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 16.1383 - mean_squared_error: 0.0323\n",
      "\n",
      "Epoch 00088: mean_squared_error improved from 0.03236 to 0.03228, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 89/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 18.3287 - mean_squared_error: 0.0402\n",
      "\n",
      "Epoch 00089: mean_squared_error did not improve from 0.03228\n",
      "Epoch 90/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 14.9429 - mean_squared_error: 0.0285\n",
      "\n",
      "Epoch 00090: mean_squared_error improved from 0.03228 to 0.02845, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 91/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 16.0800 - mean_squared_error: 0.0326\n",
      "\n",
      "Epoch 00091: mean_squared_error did not improve from 0.02845\n",
      "Epoch 92/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 15.5619 - mean_squared_error: 0.0309\n",
      "\n",
      "Epoch 00092: mean_squared_error did not improve from 0.02845\n",
      "Epoch 93/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 16.1361 - mean_squared_error: 0.0328\n",
      "\n",
      "Epoch 00093: mean_squared_error did not improve from 0.02845\n",
      "Epoch 94/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 15.4187 - mean_squared_error: 0.0304\n",
      "\n",
      "Epoch 00094: mean_squared_error did not improve from 0.02845\n",
      "Epoch 95/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 14.8342 - mean_squared_error: 0.0285\n",
      "\n",
      "Epoch 00095: mean_squared_error did not improve from 0.02845\n",
      "Epoch 96/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 15.1453 - mean_squared_error: 0.0296\n",
      "\n",
      "Epoch 00096: mean_squared_error did not improve from 0.02845\n",
      "Epoch 97/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 14.3120 - mean_squared_error: 0.0266\n",
      "\n",
      "Epoch 00097: mean_squared_error improved from 0.02845 to 0.02656, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 98/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 14.6755 - mean_squared_error: 0.0278\n",
      "\n",
      "Epoch 00098: mean_squared_error did not improve from 0.02656\n",
      "Epoch 99/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 14.1092 - mean_squared_error: 0.0259\n",
      "\n",
      "Epoch 00099: mean_squared_error improved from 0.02656 to 0.02588, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 100/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 13.8632 - mean_squared_error: 0.0252\n",
      "\n",
      "Epoch 00100: mean_squared_error improved from 0.02588 to 0.02518, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 101/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 13.5272 - mean_squared_error: 0.0242\n",
      "\n",
      "Epoch 00101: mean_squared_error improved from 0.02518 to 0.02419, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 102/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 14.2136 - mean_squared_error: 0.0267\n",
      "\n",
      "Epoch 00102: mean_squared_error did not improve from 0.02419\n",
      "Epoch 103/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 12.9387 - mean_squared_error: 0.0223\n",
      "\n",
      "Epoch 00103: mean_squared_error improved from 0.02419 to 0.02234, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 104/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 12.9085 - mean_squared_error: 0.0223\n",
      "\n",
      "Epoch 00104: mean_squared_error improved from 0.02234 to 0.02234, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 105/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 12.9759 - mean_squared_error: 0.0228\n",
      "\n",
      "Epoch 00105: mean_squared_error did not improve from 0.02234\n",
      "Epoch 106/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 13.2125 - mean_squared_error: 0.0238\n",
      "\n",
      "Epoch 00106: mean_squared_error did not improve from 0.02234\n",
      "Epoch 107/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 12.9659 - mean_squared_error: 0.0231\n",
      "\n",
      "Epoch 00107: mean_squared_error did not improve from 0.02234\n",
      "Epoch 108/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 13.2715 - mean_squared_error: 0.0241\n",
      "\n",
      "Epoch 00108: mean_squared_error did not improve from 0.02234\n",
      "Epoch 109/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 12.8961 - mean_squared_error: 0.0228\n",
      "\n",
      "Epoch 00109: mean_squared_error did not improve from 0.02234\n",
      "Epoch 110/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 12.5794 - mean_squared_error: 0.0218\n",
      "\n",
      "Epoch 00110: mean_squared_error improved from 0.02234 to 0.02178, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 111/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 12.3723 - mean_squared_error: 0.0211\n",
      "\n",
      "Epoch 00111: mean_squared_error improved from 0.02178 to 0.02112, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 112/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 12.4867 - mean_squared_error: 0.0216\n",
      "\n",
      "Epoch 00112: mean_squared_error did not improve from 0.02112\n",
      "Epoch 113/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 12.7976 - mean_squared_error: 0.0227\n",
      "\n",
      "Epoch 00113: mean_squared_error did not improve from 0.02112\n",
      "Epoch 114/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 12.0666 - mean_squared_error: 0.0201\n",
      "\n",
      "Epoch 00114: mean_squared_error improved from 0.02112 to 0.02013, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 115/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 12.6652 - mean_squared_error: 0.0223\n",
      "\n",
      "Epoch 00115: mean_squared_error did not improve from 0.02013\n",
      "Epoch 116/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.7005 - mean_squared_error: 0.0189\n",
      "\n",
      "Epoch 00116: mean_squared_error improved from 0.02013 to 0.01890, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 117/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 12.0664 - mean_squared_error: 0.0203\n",
      "\n",
      "Epoch 00117: mean_squared_error did not improve from 0.01890\n",
      "Epoch 118/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 11.8696 - mean_squared_error: 0.0197\n",
      "\n",
      "Epoch 00118: mean_squared_error did not improve from 0.01890\n",
      "Epoch 119/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 12.0102 - mean_squared_error: 0.0203\n",
      "\n",
      "Epoch 00119: mean_squared_error did not improve from 0.01890\n",
      "Epoch 120/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 11.7608 - mean_squared_error: 0.0195\n",
      "\n",
      "Epoch 00120: mean_squared_error did not improve from 0.01890\n",
      "Epoch 121/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 14ms/step - loss: 11.2733 - mean_squared_error: 0.0178\n",
      "\n",
      "Epoch 00121: mean_squared_error improved from 0.01890 to 0.01777, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 122/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.8238 - mean_squared_error: 0.0198\n",
      "\n",
      "Epoch 00122: mean_squared_error did not improve from 0.01777\n",
      "Epoch 123/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.8151 - mean_squared_error: 0.0199\n",
      "\n",
      "Epoch 00123: mean_squared_error did not improve from 0.01777\n",
      "Epoch 124/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 11.5368 - mean_squared_error: 0.0190\n",
      "\n",
      "Epoch 00124: mean_squared_error did not improve from 0.01777\n",
      "Epoch 125/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.6944 - mean_squared_error: 0.0197\n",
      "\n",
      "Epoch 00125: mean_squared_error did not improve from 0.01777\n",
      "Epoch 126/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.2133 - mean_squared_error: 0.0180\n",
      "\n",
      "Epoch 00126: mean_squared_error did not improve from 0.01777\n",
      "Epoch 127/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 11.4595 - mean_squared_error: 0.0188\n",
      "\n",
      "Epoch 00127: mean_squared_error did not improve from 0.01777\n",
      "Epoch 128/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.1623 - mean_squared_error: 0.0177\n",
      "\n",
      "Epoch 00128: mean_squared_error improved from 0.01777 to 0.01770, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 129/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 11.4078 - mean_squared_error: 0.0186\n",
      "\n",
      "Epoch 00129: mean_squared_error did not improve from 0.01770\n",
      "Epoch 130/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.7372 - mean_squared_error: 0.0198\n",
      "\n",
      "Epoch 00130: mean_squared_error did not improve from 0.01770\n",
      "Epoch 131/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 11.1321 - mean_squared_error: 0.0176\n",
      "\n",
      "Epoch 00131: mean_squared_error improved from 0.01770 to 0.01762, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 132/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 11.7361 - mean_squared_error: 0.0197\n",
      "\n",
      "Epoch 00132: mean_squared_error did not improve from 0.01762\n",
      "Epoch 133/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.1154 - mean_squared_error: 0.0174\n",
      "\n",
      "Epoch 00133: mean_squared_error improved from 0.01762 to 0.01737, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 134/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 10.9780 - mean_squared_error: 0.0168\n",
      "\n",
      "Epoch 00134: mean_squared_error improved from 0.01737 to 0.01676, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 135/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 10.9370 - mean_squared_error: 0.0165\n",
      "\n",
      "Epoch 00135: mean_squared_error improved from 0.01676 to 0.01655, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 136/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 12.0938 - mean_squared_error: 0.0206\n",
      "\n",
      "Epoch 00136: mean_squared_error did not improve from 0.01655\n",
      "Epoch 137/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.8386 - mean_squared_error: 0.0161\n",
      "\n",
      "Epoch 00137: mean_squared_error improved from 0.01655 to 0.01611, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 138/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 10.7722 - mean_squared_error: 0.0158\n",
      "\n",
      "Epoch 00138: mean_squared_error improved from 0.01611 to 0.01584, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 139/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.1535 - mean_squared_error: 0.0172\n",
      "\n",
      "Epoch 00139: mean_squared_error did not improve from 0.01584\n",
      "Epoch 140/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 11.4841 - mean_squared_error: 0.0185\n",
      "\n",
      "Epoch 00140: mean_squared_error did not improve from 0.01584\n",
      "Epoch 141/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 11.5061 - mean_squared_error: 0.0186\n",
      "\n",
      "Epoch 00141: mean_squared_error did not improve from 0.01584\n",
      "Epoch 142/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.4971 - mean_squared_error: 0.0184\n",
      "\n",
      "Epoch 00142: mean_squared_error did not improve from 0.01584\n",
      "Epoch 143/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 11.1074 - mean_squared_error: 0.0170\n",
      "\n",
      "Epoch 00143: mean_squared_error did not improve from 0.01584\n",
      "Epoch 144/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.7612 - mean_squared_error: 0.0192\n",
      "\n",
      "Epoch 00144: mean_squared_error did not improve from 0.01584\n",
      "Epoch 145/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.7762 - mean_squared_error: 0.0156\n",
      "\n",
      "Epoch 00145: mean_squared_error improved from 0.01584 to 0.01561, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 146/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.3025 - mean_squared_error: 0.0174\n",
      "\n",
      "Epoch 00146: mean_squared_error did not improve from 0.01561\n",
      "Epoch 147/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 10.7254 - mean_squared_error: 0.0154\n",
      "\n",
      "Epoch 00147: mean_squared_error improved from 0.01561 to 0.01537, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 148/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.8169 - mean_squared_error: 0.0158\n",
      "\n",
      "Epoch 00148: mean_squared_error did not improve from 0.01537\n",
      "Epoch 149/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.8092 - mean_squared_error: 0.0158\n",
      "\n",
      "Epoch 00149: mean_squared_error did not improve from 0.01537\n",
      "Epoch 150/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 10.5035 - mean_squared_error: 0.0148\n",
      "\n",
      "Epoch 00150: mean_squared_error improved from 0.01537 to 0.01479, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 151/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.2765 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00151: mean_squared_error improved from 0.01479 to 0.01413, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 152/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.7418 - mean_squared_error: 0.0160\n",
      "\n",
      "Epoch 00152: mean_squared_error did not improve from 0.01413\n",
      "Epoch 153/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.2196 - mean_squared_error: 0.0145\n",
      "\n",
      "Epoch 00153: mean_squared_error did not improve from 0.01413\n",
      "Epoch 154/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 11.4949 - mean_squared_error: 0.0192\n",
      "\n",
      "Epoch 00154: mean_squared_error did not improve from 0.01413\n",
      "Epoch 155/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 11.0388 - mean_squared_error: 0.0176\n",
      "\n",
      "Epoch 00155: mean_squared_error did not improve from 0.01413\n",
      "Epoch 156/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 10.6947 - mean_squared_error: 0.0161\n",
      "\n",
      "Epoch 00156: mean_squared_error did not improve from 0.01413\n",
      "Epoch 157/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.5952 - mean_squared_error: 0.0156\n",
      "\n",
      "Epoch 00157: mean_squared_error did not improve from 0.01413\n",
      "Epoch 158/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.2218 - mean_squared_error: 0.0144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00158: mean_squared_error did not improve from 0.01413\n",
      "Epoch 159/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.3668 - mean_squared_error: 0.0150\n",
      "\n",
      "Epoch 00159: mean_squared_error did not improve from 0.01413\n",
      "Epoch 160/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 11.3677 - mean_squared_error: 0.0186\n",
      "\n",
      "Epoch 00160: mean_squared_error did not improve from 0.01413\n",
      "Epoch 161/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.1525 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00161: mean_squared_error improved from 0.01413 to 0.01413, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 162/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.7610 - mean_squared_error: 0.0162\n",
      "\n",
      "Epoch 00162: mean_squared_error did not improve from 0.01413\n",
      "Epoch 163/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.2255 - mean_squared_error: 0.0143\n",
      "\n",
      "Epoch 00163: mean_squared_error did not improve from 0.01413\n",
      "Epoch 164/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.8648 - mean_squared_error: 0.0167\n",
      "\n",
      "Epoch 00164: mean_squared_error did not improve from 0.01413\n",
      "Epoch 165/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.2989 - mean_squared_error: 0.0147\n",
      "\n",
      "Epoch 00165: mean_squared_error did not improve from 0.01413\n",
      "Epoch 166/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.1210 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00166: mean_squared_error improved from 0.01413 to 0.01403, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 167/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.1663 - mean_squared_error: 0.0142\n",
      "\n",
      "Epoch 00167: mean_squared_error did not improve from 0.01403\n",
      "Epoch 168/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.4935 - mean_squared_error: 0.0154\n",
      "\n",
      "Epoch 00168: mean_squared_error did not improve from 0.01403\n",
      "Epoch 169/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.9287 - mean_squared_error: 0.0135\n",
      "\n",
      "Epoch 00169: mean_squared_error improved from 0.01403 to 0.01348, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 170/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.5211 - mean_squared_error: 0.0157\n",
      "\n",
      "Epoch 00170: mean_squared_error did not improve from 0.01348\n",
      "Epoch 171/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8104 - mean_squared_error: 0.0133\n",
      "\n",
      "Epoch 00171: mean_squared_error improved from 0.01348 to 0.01330, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 172/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.3992 - mean_squared_error: 0.0155\n",
      "\n",
      "Epoch 00172: mean_squared_error did not improve from 0.01330\n",
      "Epoch 173/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.3017 - mean_squared_error: 0.0153\n",
      "\n",
      "Epoch 00173: mean_squared_error did not improve from 0.01330\n",
      "Epoch 174/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9404 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00174: mean_squared_error did not improve from 0.01330\n",
      "Epoch 175/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.0494 - mean_squared_error: 0.0144\n",
      "\n",
      "Epoch 00175: mean_squared_error did not improve from 0.01330\n",
      "Epoch 176/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.7269 - mean_squared_error: 0.0133\n",
      "\n",
      "Epoch 00176: mean_squared_error did not improve from 0.01330\n",
      "Epoch 177/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.7998 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00177: mean_squared_error did not improve from 0.01330\n",
      "Epoch 178/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.1225 - mean_squared_error: 0.0148\n",
      "\n",
      "Epoch 00178: mean_squared_error did not improve from 0.01330\n",
      "Epoch 179/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.8759 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00179: mean_squared_error did not improve from 0.01330\n",
      "Epoch 180/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 10.3526 - mean_squared_error: 0.0158\n",
      "\n",
      "Epoch 00180: mean_squared_error did not improve from 0.01330\n",
      "Epoch 181/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.4451 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00181: mean_squared_error improved from 0.01330 to 0.01259, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 182/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7013 - mean_squared_error: 0.0135\n",
      "\n",
      "Epoch 00182: mean_squared_error did not improve from 0.01259\n",
      "Epoch 183/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4611 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 00183: mean_squared_error did not improve from 0.01259\n",
      "Epoch 184/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.6989 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00184: mean_squared_error did not improve from 0.01259\n",
      "Epoch 185/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8811 - mean_squared_error: 0.0146\n",
      "\n",
      "Epoch 00185: mean_squared_error did not improve from 0.01259\n",
      "Epoch 186/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8374 - mean_squared_error: 0.0145\n",
      "\n",
      "Epoch 00186: mean_squared_error did not improve from 0.01259\n",
      "Epoch 187/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9799 - mean_squared_error: 0.0150\n",
      "\n",
      "Epoch 00187: mean_squared_error did not improve from 0.01259\n",
      "Epoch 188/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.0536 - mean_squared_error: 0.0152\n",
      "\n",
      "Epoch 00188: mean_squared_error did not improve from 0.01259\n",
      "Epoch 189/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7953 - mean_squared_error: 0.0142\n",
      "\n",
      "Epoch 00189: mean_squared_error did not improve from 0.01259\n",
      "Epoch 190/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2717 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00190: mean_squared_error improved from 0.01259 to 0.01236, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 191/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9237 - mean_squared_error: 0.0147\n",
      "\n",
      "Epoch 00191: mean_squared_error did not improve from 0.01236\n",
      "Epoch 192/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.5689 - mean_squared_error: 0.0134\n",
      "\n",
      "Epoch 00192: mean_squared_error did not improve from 0.01236\n",
      "Epoch 193/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.6408 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00193: mean_squared_error did not improve from 0.01236\n",
      "Epoch 194/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8947 - mean_squared_error: 0.0144\n",
      "\n",
      "Epoch 00194: mean_squared_error did not improve from 0.01236\n",
      "Epoch 195/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9193 - mean_squared_error: 0.0144\n",
      "\n",
      "Epoch 00195: mean_squared_error did not improve from 0.01236\n",
      "Epoch 196/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4482 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00196: mean_squared_error did not improve from 0.01236\n",
      "Epoch 197/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8091 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00197: mean_squared_error did not improve from 0.01236\n",
      "Epoch 198/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2458 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00198: mean_squared_error improved from 0.01236 to 0.01189, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 199/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4228 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00199: mean_squared_error did not improve from 0.01189\n",
      "Epoch 200/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9611 - mean_squared_error: 0.0146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00200: mean_squared_error did not improve from 0.01189\n",
      "Epoch 201/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8037 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00201: mean_squared_error did not improve from 0.01189\n",
      "Epoch 202/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.3702 - mean_squared_error: 0.0160\n",
      "\n",
      "Epoch 00202: mean_squared_error did not improve from 0.01189\n",
      "Epoch 203/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.3569 - mean_squared_error: 0.0160\n",
      "\n",
      "Epoch 00203: mean_squared_error did not improve from 0.01189\n",
      "Epoch 204/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4633 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00204: mean_squared_error did not improve from 0.01189\n",
      "Epoch 205/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.0987 - mean_squared_error: 0.0148\n",
      "\n",
      "Epoch 00205: mean_squared_error did not improve from 0.01189\n",
      "Epoch 206/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.7335 - mean_squared_error: 0.0134\n",
      "\n",
      "Epoch 00206: mean_squared_error did not improve from 0.01189\n",
      "Epoch 207/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.6288 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00207: mean_squared_error did not improve from 0.01189\n",
      "Epoch 208/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9463 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00208: mean_squared_error did not improve from 0.01189\n",
      "Epoch 209/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9749 - mean_squared_error: 0.0142\n",
      "\n",
      "Epoch 00209: mean_squared_error did not improve from 0.01189\n",
      "Epoch 210/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.2641 - mean_squared_error: 0.0152\n",
      "\n",
      "Epoch 00210: mean_squared_error did not improve from 0.01189\n",
      "Epoch 211/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.6799 - mean_squared_error: 0.0131\n",
      "\n",
      "Epoch 00211: mean_squared_error did not improve from 0.01189\n",
      "Epoch 212/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7931 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00212: mean_squared_error did not improve from 0.01189\n",
      "Epoch 213/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4824 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00213: mean_squared_error did not improve from 0.01189\n",
      "Epoch 214/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2995 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00214: mean_squared_error did not improve from 0.01189\n",
      "Epoch 215/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.1236 - mean_squared_error: 0.0149\n",
      "\n",
      "Epoch 00215: mean_squared_error did not improve from 0.01189\n",
      "Epoch 216/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7016 - mean_squared_error: 0.0134\n",
      "\n",
      "Epoch 00216: mean_squared_error did not improve from 0.01189\n",
      "Epoch 217/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.8497 - mean_squared_error: 0.0174\n",
      "\n",
      "Epoch 00217: mean_squared_error did not improve from 0.01189\n",
      "Epoch 218/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.1411 - mean_squared_error: 0.0149\n",
      "\n",
      "Epoch 00218: mean_squared_error did not improve from 0.01189\n",
      "Epoch 219/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.5700 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00219: mean_squared_error did not improve from 0.01189\n",
      "Epoch 220/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.7111 - mean_squared_error: 0.0169\n",
      "\n",
      "Epoch 00220: mean_squared_error did not improve from 0.01189\n",
      "Epoch 221/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.6482 - mean_squared_error: 0.0130\n",
      "\n",
      "Epoch 00221: mean_squared_error did not improve from 0.01189\n",
      "Epoch 222/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.3839 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00222: mean_squared_error did not improve from 0.01189\n",
      "Epoch 223/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.9847 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00223: mean_squared_error did not improve from 0.01189\n",
      "Epoch 224/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.9192 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00224: mean_squared_error did not improve from 0.01189\n",
      "Epoch 225/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.4426 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00225: mean_squared_error did not improve from 0.01189\n",
      "Epoch 226/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7880 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00226: mean_squared_error did not improve from 0.01189\n",
      "Epoch 227/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.5137 - mean_squared_error: 0.0131\n",
      "\n",
      "Epoch 00227: mean_squared_error did not improve from 0.01189\n",
      "Epoch 228/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.6301 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00228: mean_squared_error did not improve from 0.01189\n",
      "Epoch 229/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0473 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00229: mean_squared_error improved from 0.01189 to 0.01160, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 230/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.6175 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00230: mean_squared_error did not improve from 0.01160\n",
      "Epoch 231/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.9789 - mean_squared_error: 0.0152\n",
      "\n",
      "Epoch 00231: mean_squared_error did not improve from 0.01160\n",
      "Epoch 232/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.8457 - mean_squared_error: 0.0146\n",
      "\n",
      "Epoch 00232: mean_squared_error did not improve from 0.01160\n",
      "Epoch 233/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0952 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00233: mean_squared_error did not improve from 0.01160\n",
      "Epoch 234/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.4046 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00234: mean_squared_error did not improve from 0.01160\n",
      "Epoch 235/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 9.1450 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00235: mean_squared_error did not improve from 0.01160\n",
      "Epoch 236/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 9.0880 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00236: mean_squared_error did not improve from 0.01160\n",
      "Epoch 237/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 9.2517 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00237: mean_squared_error did not improve from 0.01160\n",
      "Epoch 238/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 9.0671 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00238: mean_squared_error did not improve from 0.01160\n",
      "Epoch 239/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.5162 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00239: mean_squared_error did not improve from 0.01160\n",
      "Epoch 240/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4539 - mean_squared_error: 0.0139\n",
      "\n",
      "Epoch 00240: mean_squared_error did not improve from 0.01160\n",
      "Epoch 241/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.3467 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00241: mean_squared_error did not improve from 0.01160\n",
      "Epoch 242/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0450 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00242: mean_squared_error did not improve from 0.01160\n",
      "Epoch 243/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 10.1566 - mean_squared_error: 0.0166\n",
      "\n",
      "Epoch 00243: mean_squared_error did not improve from 0.01160\n",
      "Epoch 244/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.8488 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00244: mean_squared_error did not improve from 0.01160\n",
      "Epoch 245/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.4343 - mean_squared_error: 0.0174\n",
      "\n",
      "Epoch 00245: mean_squared_error did not improve from 0.01160\n",
      "Epoch 246/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9040 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00246: mean_squared_error did not improve from 0.01160\n",
      "Epoch 247/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2554 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00247: mean_squared_error did not improve from 0.01160\n",
      "Epoch 248/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4720 - mean_squared_error: 0.0134\n",
      "\n",
      "Epoch 00248: mean_squared_error did not improve from 0.01160\n",
      "Epoch 249/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2642 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00249: mean_squared_error did not improve from 0.01160\n",
      "Epoch 250/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1705 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00250: mean_squared_error did not improve from 0.01160\n",
      "Epoch 251/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9222 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00251: mean_squared_error improved from 0.01160 to 0.01141, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 252/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9238 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00252: mean_squared_error did not improve from 0.01141\n",
      "Epoch 253/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9745 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00253: mean_squared_error did not improve from 0.01141\n",
      "Epoch 254/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0231 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00254: mean_squared_error did not improve from 0.01141\n",
      "Epoch 255/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.1062 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00255: mean_squared_error did not improve from 0.01141\n",
      "Epoch 256/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9902 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00256: mean_squared_error did not improve from 0.01141\n",
      "Epoch 257/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3316 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00257: mean_squared_error did not improve from 0.01141\n",
      "Epoch 258/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.4883 - mean_squared_error: 0.0143\n",
      "\n",
      "Epoch 00258: mean_squared_error did not improve from 0.01141\n",
      "Epoch 259/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.5137 - mean_squared_error: 0.0143\n",
      "\n",
      "Epoch 00259: mean_squared_error did not improve from 0.01141\n",
      "Epoch 260/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4136 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00260: mean_squared_error did not improve from 0.01141\n",
      "Epoch 261/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4748 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00261: mean_squared_error did not improve from 0.01141\n",
      "Epoch 262/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1502 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00262: mean_squared_error did not improve from 0.01141\n",
      "Epoch 263/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9576 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00263: mean_squared_error improved from 0.01141 to 0.01139, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 264/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9522 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00264: mean_squared_error improved from 0.01139 to 0.01127, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 265/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2906 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00265: mean_squared_error did not improve from 0.01127\n",
      "Epoch 266/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3810 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00266: mean_squared_error did not improve from 0.01127\n",
      "Epoch 267/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1548 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00267: mean_squared_error did not improve from 0.01127\n",
      "Epoch 268/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8463 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00268: mean_squared_error improved from 0.01127 to 0.01104, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 269/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7826 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00269: mean_squared_error improved from 0.01104 to 0.01090, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 270/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8859 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00270: mean_squared_error did not improve from 0.01090\n",
      "Epoch 271/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8556 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00271: mean_squared_error did not improve from 0.01090\n",
      "Epoch 272/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8172 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00272: mean_squared_error did not improve from 0.01090\n",
      "Epoch 273/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7482 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00273: mean_squared_error did not improve from 0.01090\n",
      "Epoch 274/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0012 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00274: mean_squared_error did not improve from 0.01090\n",
      "Epoch 275/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2225 - mean_squared_error: 0.0135\n",
      "\n",
      "Epoch 00275: mean_squared_error did not improve from 0.01090\n",
      "Epoch 276/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.6040 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00276: mean_squared_error did not improve from 0.01090\n",
      "Epoch 277/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.8471 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00277: mean_squared_error did not improve from 0.01090\n",
      "Epoch 278/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6115 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00278: mean_squared_error did not improve from 0.01090\n",
      "Epoch 279/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.3611 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00279: mean_squared_error did not improve from 0.01090\n",
      "Epoch 280/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.7859 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00280: mean_squared_error did not improve from 0.01090\n",
      "Epoch 281/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8306 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 00281: mean_squared_error did not improve from 0.01090\n",
      "Epoch 282/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.0567 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00282: mean_squared_error did not improve from 0.01090\n",
      "Epoch 283/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1542 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00283: mean_squared_error did not improve from 0.01090\n",
      "Epoch 284/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4084 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00284: mean_squared_error did not improve from 0.01090\n",
      "Epoch 285/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8954 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00285: mean_squared_error did not improve from 0.01090\n",
      "Epoch 286/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2289 - mean_squared_error: 0.0139\n",
      "\n",
      "Epoch 00286: mean_squared_error did not improve from 0.01090\n",
      "Epoch 287/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7573 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00287: mean_squared_error did not improve from 0.01090\n",
      "Epoch 288/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2893 - mean_squared_error: 0.0137\n",
      "\n",
      "Epoch 00288: mean_squared_error did not improve from 0.01090\n",
      "Epoch 289/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.6238 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00289: mean_squared_error did not improve from 0.01090\n",
      "Epoch 290/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1450 - mean_squared_error: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00290: mean_squared_error did not improve from 0.01090\n",
      "Epoch 291/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3548 - mean_squared_error: 0.0136\n",
      "\n",
      "Epoch 00291: mean_squared_error did not improve from 0.01090\n",
      "Epoch 292/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7896 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00292: mean_squared_error did not improve from 0.01090\n",
      "Epoch 293/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0335 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00293: mean_squared_error did not improve from 0.01090\n",
      "Epoch 294/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0191 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00294: mean_squared_error did not improve from 0.01090\n",
      "Epoch 295/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9577 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00295: mean_squared_error did not improve from 0.01090\n",
      "Epoch 296/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0399 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00296: mean_squared_error did not improve from 0.01090\n",
      "Epoch 297/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1314 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00297: mean_squared_error did not improve from 0.01090\n",
      "Epoch 298/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7450 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00298: mean_squared_error did not improve from 0.01090\n",
      "Epoch 299/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5756 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00299: mean_squared_error improved from 0.01090 to 0.01076, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 300/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8274 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00300: mean_squared_error did not improve from 0.01076\n",
      "Epoch 301/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4829 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00301: mean_squared_error improved from 0.01076 to 0.01060, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 302/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.8996 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00302: mean_squared_error did not improve from 0.01060\n",
      "Epoch 303/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.6082 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00303: mean_squared_error did not improve from 0.01060\n",
      "Epoch 304/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3966 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00304: mean_squared_error improved from 0.01060 to 0.01056, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 305/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.1296 - mean_squared_error: 0.0133\n",
      "\n",
      "Epoch 00305: mean_squared_error did not improve from 0.01056\n",
      "Epoch 306/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.8614 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00306: mean_squared_error did not improve from 0.01056\n",
      "Epoch 307/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.7499 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00307: mean_squared_error did not improve from 0.01056\n",
      "Epoch 308/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9996 - mean_squared_error: 0.0130\n",
      "\n",
      "Epoch 00308: mean_squared_error did not improve from 0.01056\n",
      "Epoch 309/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.8729 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00309: mean_squared_error did not improve from 0.01056\n",
      "Epoch 310/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1779 - mean_squared_error: 0.0135\n",
      "\n",
      "Epoch 00310: mean_squared_error did not improve from 0.01056\n",
      "Epoch 311/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7786 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00311: mean_squared_error did not improve from 0.01056\n",
      "Epoch 312/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7435 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00312: mean_squared_error did not improve from 0.01056\n",
      "Epoch 313/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 9.0486 - mean_squared_error: 0.0132\n",
      "\n",
      "Epoch 00313: mean_squared_error did not improve from 0.01056\n",
      "Epoch 314/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.5499 - mean_squared_error: 0.0150\n",
      "\n",
      "Epoch 00314: mean_squared_error did not improve from 0.01056\n",
      "Epoch 315/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0793 - mean_squared_error: 0.0132\n",
      "\n",
      "Epoch 00315: mean_squared_error did not improve from 0.01056\n",
      "Epoch 316/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6855 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00316: mean_squared_error did not improve from 0.01056\n",
      "Epoch 317/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0409 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 00317: mean_squared_error did not improve from 0.01056\n",
      "Epoch 318/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.7480 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00318: mean_squared_error did not improve from 0.01056\n",
      "Epoch 319/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.8636 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00319: mean_squared_error did not improve from 0.01056\n",
      "Epoch 320/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9805 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00320: mean_squared_error did not improve from 0.01056\n",
      "Epoch 321/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.2601 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00321: mean_squared_error did not improve from 0.01056\n",
      "Epoch 322/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5244 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00322: mean_squared_error did not improve from 0.01056\n",
      "Epoch 323/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7779 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00323: mean_squared_error did not improve from 0.01056\n",
      "Epoch 324/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 9.0248 - mean_squared_error: 0.0130\n",
      "\n",
      "Epoch 00324: mean_squared_error did not improve from 0.01056\n",
      "Epoch 325/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.5545 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00325: mean_squared_error did not improve from 0.01056\n",
      "Epoch 326/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.8259 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00326: mean_squared_error did not improve from 0.01056\n",
      "Epoch 327/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5007 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00327: mean_squared_error did not improve from 0.01056\n",
      "Epoch 328/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.9195 - mean_squared_error: 0.0130\n",
      "\n",
      "Epoch 00328: mean_squared_error did not improve from 0.01056\n",
      "Epoch 329/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5221 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00329: mean_squared_error did not improve from 0.01056\n",
      "Epoch 330/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4282 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00330: mean_squared_error did not improve from 0.01056\n",
      "Epoch 331/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5923 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00331: mean_squared_error did not improve from 0.01056\n",
      "Epoch 332/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4383 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00332: mean_squared_error did not improve from 0.01056\n",
      "Epoch 333/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7097 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00333: mean_squared_error did not improve from 0.01056\n",
      "Epoch 334/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3333 - mean_squared_error: 0.0149\n",
      "\n",
      "Epoch 00334: mean_squared_error did not improve from 0.01056\n",
      "Epoch 335/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8210 - mean_squared_error: 0.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00335: mean_squared_error did not improve from 0.01056\n",
      "Epoch 336/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8229 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00336: mean_squared_error did not improve from 0.01056\n",
      "Epoch 337/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7410 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00337: mean_squared_error did not improve from 0.01056\n",
      "Epoch 338/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7939 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00338: mean_squared_error did not improve from 0.01056\n",
      "Epoch 339/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8013 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00339: mean_squared_error did not improve from 0.01056\n",
      "Epoch 340/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6763 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00340: mean_squared_error did not improve from 0.01056\n",
      "Epoch 341/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5484 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00341: mean_squared_error did not improve from 0.01056\n",
      "Epoch 342/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7479 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00342: mean_squared_error did not improve from 0.01056\n",
      "Epoch 343/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7184 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00343: mean_squared_error did not improve from 0.01056\n",
      "Epoch 344/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4971 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00344: mean_squared_error did not improve from 0.01056\n",
      "Epoch 345/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7029 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00345: mean_squared_error did not improve from 0.01056\n",
      "Epoch 346/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4365 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00346: mean_squared_error did not improve from 0.01056\n",
      "Epoch 347/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6061 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00347: mean_squared_error did not improve from 0.01056\n",
      "Epoch 348/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2673 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00348: mean_squared_error did not improve from 0.01056\n",
      "Epoch 349/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7397 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00349: mean_squared_error did not improve from 0.01056\n",
      "Epoch 350/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.7096 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00350: mean_squared_error did not improve from 0.01056\n",
      "Epoch 351/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.7036 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00351: mean_squared_error did not improve from 0.01056\n",
      "Epoch 352/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5714 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00352: mean_squared_error did not improve from 0.01056\n",
      "Epoch 353/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7739 - mean_squared_error: 0.0163\n",
      "\n",
      "Epoch 00353: mean_squared_error did not improve from 0.01056\n",
      "Epoch 354/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.2239 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00354: mean_squared_error did not improve from 0.01056\n",
      "Epoch 355/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3255 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00355: mean_squared_error did not improve from 0.01056\n",
      "Epoch 356/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5779 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00356: mean_squared_error did not improve from 0.01056\n",
      "Epoch 357/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3091 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00357: mean_squared_error did not improve from 0.01056\n",
      "Epoch 358/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3248 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00358: mean_squared_error did not improve from 0.01056\n",
      "Epoch 359/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5481 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00359: mean_squared_error did not improve from 0.01056\n",
      "Epoch 360/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2662 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00360: mean_squared_error did not improve from 0.01056\n",
      "Epoch 361/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.0962 - mean_squared_error: 0.0139\n",
      "\n",
      "Epoch 00361: mean_squared_error did not improve from 0.01056\n",
      "Epoch 362/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2602 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00362: mean_squared_error did not improve from 0.01056\n",
      "Epoch 363/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1676 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00363: mean_squared_error did not improve from 0.01056\n",
      "Epoch 364/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4402 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00364: mean_squared_error did not improve from 0.01056\n",
      "Epoch 365/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4368 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00365: mean_squared_error did not improve from 0.01056\n",
      "Epoch 366/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3285 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00366: mean_squared_error did not improve from 0.01056\n",
      "Epoch 367/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3990 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00367: mean_squared_error did not improve from 0.01056\n",
      "Epoch 368/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3325 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00368: mean_squared_error did not improve from 0.01056\n",
      "Epoch 369/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1517 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00369: mean_squared_error did not improve from 0.01056\n",
      "Epoch 370/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9387 - mean_squared_error: 0.0139\n",
      "\n",
      "Epoch 00370: mean_squared_error did not improve from 0.01056\n",
      "Epoch 371/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2965 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00371: mean_squared_error did not improve from 0.01056\n",
      "Epoch 372/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3107 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00372: mean_squared_error did not improve from 0.01056\n",
      "Epoch 373/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1832 - mean_squared_error: 0.0144\n",
      "\n",
      "Epoch 00373: mean_squared_error did not improve from 0.01056\n",
      "Epoch 374/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2136 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00374: mean_squared_error did not improve from 0.01056\n",
      "Epoch 375/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3372 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00375: mean_squared_error did not improve from 0.01056\n",
      "Epoch 376/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6134 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00376: mean_squared_error did not improve from 0.01056\n",
      "Epoch 377/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5666 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00377: mean_squared_error did not improve from 0.01056\n",
      "Epoch 378/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1769 - mean_squared_error: 0.0147\n",
      "\n",
      "Epoch 00378: mean_squared_error did not improve from 0.01056\n",
      "Epoch 379/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5446 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00379: mean_squared_error did not improve from 0.01056\n",
      "Epoch 380/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6155 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00380: mean_squared_error did not improve from 0.01056\n",
      "Epoch 381/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6467 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00381: mean_squared_error did not improve from 0.01056\n",
      "Epoch 382/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2921 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00382: mean_squared_error did not improve from 0.01056\n",
      "Epoch 383/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7260 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00383: mean_squared_error did not improve from 0.01056\n",
      "Epoch 384/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3593 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00384: mean_squared_error did not improve from 0.01056\n",
      "Epoch 385/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4544 - mean_squared_error: 0.0150\n",
      "\n",
      "Epoch 00385: mean_squared_error did not improve from 0.01056\n",
      "Epoch 386/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.2853 - mean_squared_error: 0.0143\n",
      "\n",
      "Epoch 00386: mean_squared_error did not improve from 0.01056\n",
      "Epoch 387/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6242 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00387: mean_squared_error did not improve from 0.01056\n",
      "Epoch 388/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9881 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00388: mean_squared_error did not improve from 0.01056\n",
      "Epoch 389/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 10.0916 - mean_squared_error: 0.0164\n",
      "\n",
      "Epoch 00389: mean_squared_error did not improve from 0.01056\n",
      "Epoch 390/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7648 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00390: mean_squared_error did not improve from 0.01056\n",
      "Epoch 391/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6208 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00391: mean_squared_error did not improve from 0.01056\n",
      "Epoch 392/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.5133 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 00392: mean_squared_error did not improve from 0.01056\n",
      "Epoch 393/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.9053 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00393: mean_squared_error did not improve from 0.01056\n",
      "Epoch 394/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7212 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00394: mean_squared_error did not improve from 0.01056\n",
      "Epoch 395/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5494 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00395: mean_squared_error did not improve from 0.01056\n",
      "Epoch 396/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5296 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00396: mean_squared_error did not improve from 0.01056\n",
      "Epoch 397/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3201 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00397: mean_squared_error improved from 0.01056 to 0.01038, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 398/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7940 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00398: mean_squared_error did not improve from 0.01038\n",
      "Epoch 399/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1888 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00399: mean_squared_error did not improve from 0.01038\n",
      "Epoch 400/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3868 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00400: mean_squared_error did not improve from 0.01038\n",
      "Epoch 401/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4829 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00401: mean_squared_error did not improve from 0.01038\n",
      "Epoch 402/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5681 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00402: mean_squared_error did not improve from 0.01038\n",
      "Epoch 403/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.6292 - mean_squared_error: 0.0163\n",
      "\n",
      "Epoch 00403: mean_squared_error did not improve from 0.01038\n",
      "Epoch 404/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3810 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00404: mean_squared_error did not improve from 0.01038\n",
      "Epoch 405/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7134 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00405: mean_squared_error did not improve from 0.01038\n",
      "Epoch 406/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7148 - mean_squared_error: 0.0160\n",
      "\n",
      "Epoch 00406: mean_squared_error did not improve from 0.01038\n",
      "Epoch 407/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1170 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00407: mean_squared_error did not improve from 0.01038\n",
      "Epoch 408/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5747 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00408: mean_squared_error did not improve from 0.01038\n",
      "Epoch 409/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8698 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00409: mean_squared_error did not improve from 0.01038\n",
      "Epoch 410/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4154 - mean_squared_error: 0.0148\n",
      "\n",
      "Epoch 00410: mean_squared_error did not improve from 0.01038\n",
      "Epoch 411/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.1169 - mean_squared_error: 0.0135\n",
      "\n",
      "Epoch 00411: mean_squared_error did not improve from 0.01038\n",
      "Epoch 412/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7877 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00412: mean_squared_error did not improve from 0.01038\n",
      "Epoch 413/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7741 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00413: mean_squared_error did not improve from 0.01038\n",
      "Epoch 414/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7574 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00414: mean_squared_error did not improve from 0.01038\n",
      "Epoch 415/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.9750 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00415: mean_squared_error did not improve from 0.01038\n",
      "Epoch 416/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 8.7663 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00416: mean_squared_error did not improve from 0.01038\n",
      "Epoch 417/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4797 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00417: mean_squared_error did not improve from 0.01038\n",
      "Epoch 418/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.4677 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00418: mean_squared_error did not improve from 0.01038\n",
      "Epoch 419/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3182 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00419: mean_squared_error did not improve from 0.01038\n",
      "Epoch 420/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.1669 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00420: mean_squared_error did not improve from 0.01038\n",
      "Epoch 421/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.4028 - mean_squared_error: 0.0156\n",
      "\n",
      "Epoch 00421: mean_squared_error did not improve from 0.01038\n",
      "Epoch 422/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.6315 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00422: mean_squared_error did not improve from 0.01038\n",
      "Epoch 423/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5033 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00423: mean_squared_error did not improve from 0.01038\n",
      "Epoch 424/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3462 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00424: mean_squared_error did not improve from 0.01038\n",
      "Epoch 425/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4658 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00425: mean_squared_error did not improve from 0.01038\n",
      "Epoch 426/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.6150 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00426: mean_squared_error did not improve from 0.01038\n",
      "Epoch 427/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1219 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00427: mean_squared_error did not improve from 0.01038\n",
      "Epoch 428/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9166 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00428: mean_squared_error did not improve from 0.01038\n",
      "Epoch 429/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3637 - mean_squared_error: 0.0123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00429: mean_squared_error did not improve from 0.01038\n",
      "Epoch 430/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8430 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00430: mean_squared_error did not improve from 0.01038\n",
      "Epoch 431/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.1057 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00431: mean_squared_error did not improve from 0.01038\n",
      "Epoch 432/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0511 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00432: mean_squared_error did not improve from 0.01038\n",
      "Epoch 433/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0744 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00433: mean_squared_error did not improve from 0.01038\n",
      "Epoch 434/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2327 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00434: mean_squared_error did not improve from 0.01038\n",
      "Epoch 435/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3667 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00435: mean_squared_error did not improve from 0.01038\n",
      "Epoch 436/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.5145 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 00436: mean_squared_error did not improve from 0.01038\n",
      "Epoch 437/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0201 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00437: mean_squared_error did not improve from 0.01038\n",
      "Epoch 438/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6636 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00438: mean_squared_error improved from 0.01038 to 0.00996, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 439/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1983 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00439: mean_squared_error did not improve from 0.00996\n",
      "Epoch 440/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2268 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00440: mean_squared_error did not improve from 0.00996\n",
      "Epoch 441/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.7236 - mean_squared_error: 0.0173\n",
      "\n",
      "Epoch 00441: mean_squared_error did not improve from 0.00996\n",
      "Epoch 442/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4365 - mean_squared_error: 0.0125\n",
      "\n",
      "Epoch 00442: mean_squared_error did not improve from 0.00996\n",
      "Epoch 443/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.8616 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00443: mean_squared_error did not improve from 0.00996\n",
      "Epoch 444/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0127 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00444: mean_squared_error did not improve from 0.00996\n",
      "Epoch 445/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1498 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00445: mean_squared_error did not improve from 0.00996\n",
      "Epoch 446/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0507 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00446: mean_squared_error did not improve from 0.00996\n",
      "Epoch 447/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8579 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00447: mean_squared_error did not improve from 0.00996\n",
      "Epoch 448/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1292 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00448: mean_squared_error did not improve from 0.00996\n",
      "Epoch 449/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1035 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00449: mean_squared_error did not improve from 0.00996\n",
      "Epoch 450/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9167 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00450: mean_squared_error did not improve from 0.00996\n",
      "Epoch 451/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1714 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00451: mean_squared_error did not improve from 0.00996\n",
      "Epoch 452/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1508 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00452: mean_squared_error did not improve from 0.00996\n",
      "Epoch 453/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9491 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00453: mean_squared_error did not improve from 0.00996\n",
      "Epoch 454/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1811 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00454: mean_squared_error did not improve from 0.00996\n",
      "Epoch 455/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.9896 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00455: mean_squared_error did not improve from 0.00996\n",
      "Epoch 456/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0223 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00456: mean_squared_error did not improve from 0.00996\n",
      "Epoch 457/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9462 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00457: mean_squared_error did not improve from 0.00996\n",
      "Epoch 458/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5513 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00458: mean_squared_error improved from 0.00996 to 0.00983, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 459/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2562 - mean_squared_error: 0.0124\n",
      "\n",
      "Epoch 00459: mean_squared_error did not improve from 0.00983\n",
      "Epoch 460/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8321 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00460: mean_squared_error did not improve from 0.00983\n",
      "Epoch 461/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8446 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00461: mean_squared_error did not improve from 0.00983\n",
      "Epoch 462/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6643 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00462: mean_squared_error did not improve from 0.00983\n",
      "Epoch 463/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7392 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00463: mean_squared_error did not improve from 0.00983\n",
      "Epoch 464/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7993 - mean_squared_error: 0.0143\n",
      "\n",
      "Epoch 00464: mean_squared_error did not improve from 0.00983\n",
      "Epoch 465/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8374 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00465: mean_squared_error did not improve from 0.00983\n",
      "Epoch 466/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7398 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00466: mean_squared_error did not improve from 0.00983\n",
      "Epoch 467/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.7530 - mean_squared_error: 0.0140\n",
      "\n",
      "Epoch 00467: mean_squared_error did not improve from 0.00983\n",
      "Epoch 468/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8414 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00468: mean_squared_error did not improve from 0.00983\n",
      "Epoch 469/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9450 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00469: mean_squared_error did not improve from 0.00983\n",
      "Epoch 470/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1354 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00470: mean_squared_error did not improve from 0.00983\n",
      "Epoch 471/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1767 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00471: mean_squared_error did not improve from 0.00983\n",
      "Epoch 472/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1725 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00472: mean_squared_error did not improve from 0.00983\n",
      "Epoch 473/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9262 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00473: mean_squared_error did not improve from 0.00983\n",
      "Epoch 474/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7502 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00474: mean_squared_error did not improve from 0.00983\n",
      "Epoch 475/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8016 - mean_squared_error: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00475: mean_squared_error did not improve from 0.00983\n",
      "Epoch 476/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4563 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 00476: mean_squared_error did not improve from 0.00983\n",
      "Epoch 477/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3181 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00477: mean_squared_error did not improve from 0.00983\n",
      "Epoch 478/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9603 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00478: mean_squared_error did not improve from 0.00983\n",
      "Epoch 479/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9970 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00479: mean_squared_error did not improve from 0.00983\n",
      "Epoch 480/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6833 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00480: mean_squared_error did not improve from 0.00983\n",
      "Epoch 481/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8752 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00481: mean_squared_error did not improve from 0.00983\n",
      "Epoch 482/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9852 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00482: mean_squared_error did not improve from 0.00983\n",
      "Epoch 483/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7686 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00483: mean_squared_error did not improve from 0.00983\n",
      "Epoch 484/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9866 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00484: mean_squared_error did not improve from 0.00983\n",
      "Epoch 485/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9159 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00485: mean_squared_error did not improve from 0.00983\n",
      "Epoch 486/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 8.0562 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00486: mean_squared_error did not improve from 0.00983\n",
      "Epoch 487/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 7.7488 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00487: mean_squared_error did not improve from 0.00983\n",
      "Epoch 488/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 8.0573 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 00488: mean_squared_error did not improve from 0.00983\n",
      "Epoch 489/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6052 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00489: mean_squared_error improved from 0.00983 to 0.00977, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 490/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5746 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00490: mean_squared_error improved from 0.00977 to 0.00962, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 491/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8081 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00491: mean_squared_error did not improve from 0.00962\n",
      "Epoch 492/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7680 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00492: mean_squared_error did not improve from 0.00962\n",
      "Epoch 493/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7251 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00493: mean_squared_error did not improve from 0.00962\n",
      "Epoch 494/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1747 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00494: mean_squared_error did not improve from 0.00962\n",
      "Epoch 495/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0225 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00495: mean_squared_error did not improve from 0.00962\n",
      "Epoch 496/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5824 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00496: mean_squared_error did not improve from 0.00962\n",
      "Epoch 497/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3462 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00497: mean_squared_error improved from 0.00962 to 0.00905, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 498/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8315 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00498: mean_squared_error did not improve from 0.00905\n",
      "Epoch 499/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8433 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00499: mean_squared_error did not improve from 0.00905\n",
      "Epoch 500/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7606 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00500: mean_squared_error did not improve from 0.00905\n",
      "Epoch 501/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.3000 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00501: mean_squared_error did not improve from 0.00905\n",
      "Epoch 502/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6694 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00502: mean_squared_error did not improve from 0.00905\n",
      "Epoch 503/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1932 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00503: mean_squared_error did not improve from 0.00905\n",
      "Epoch 504/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6691 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00504: mean_squared_error did not improve from 0.00905\n",
      "Epoch 505/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5385 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00505: mean_squared_error did not improve from 0.00905\n",
      "Epoch 506/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6759 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00506: mean_squared_error did not improve from 0.00905\n",
      "Epoch 507/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4183 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00507: mean_squared_error did not improve from 0.00905\n",
      "Epoch 508/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5003 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00508: mean_squared_error did not improve from 0.00905\n",
      "Epoch 509/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8185 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00509: mean_squared_error did not improve from 0.00905\n",
      "Epoch 510/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4726 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00510: mean_squared_error did not improve from 0.00905\n",
      "Epoch 511/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6961 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00511: mean_squared_error did not improve from 0.00905\n",
      "Epoch 512/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5180 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00512: mean_squared_error did not improve from 0.00905\n",
      "Epoch 513/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4362 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00513: mean_squared_error did not improve from 0.00905\n",
      "Epoch 514/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0246 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00514: mean_squared_error did not improve from 0.00905\n",
      "Epoch 515/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4368 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00515: mean_squared_error did not improve from 0.00905\n",
      "Epoch 516/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 8.5771 - mean_squared_error: 0.0138\n",
      "\n",
      "Epoch 00516: mean_squared_error did not improve from 0.00905\n",
      "Epoch 517/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3204 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00517: mean_squared_error did not improve from 0.00905\n",
      "Epoch 518/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.7159 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00518: mean_squared_error did not improve from 0.00905\n",
      "Epoch 519/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.5267 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00519: mean_squared_error did not improve from 0.00905\n",
      "Epoch 520/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6319 - mean_squared_error: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00520: mean_squared_error did not improve from 0.00905\n",
      "Epoch 521/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4035 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00521: mean_squared_error did not improve from 0.00905\n",
      "Epoch 522/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.6210 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00522: mean_squared_error did not improve from 0.00905\n",
      "Epoch 523/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4792 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00523: mean_squared_error did not improve from 0.00905\n",
      "Epoch 524/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9886 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00524: mean_squared_error did not improve from 0.00905\n",
      "Epoch 525/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.5720 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00525: mean_squared_error did not improve from 0.00905\n",
      "Epoch 526/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3307 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00526: mean_squared_error did not improve from 0.00905\n",
      "Epoch 527/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3605 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00527: mean_squared_error did not improve from 0.00905\n",
      "Epoch 528/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3570 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00528: mean_squared_error did not improve from 0.00905\n",
      "Epoch 529/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1530 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00529: mean_squared_error did not improve from 0.00905\n",
      "Epoch 530/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4954 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00530: mean_squared_error did not improve from 0.00905\n",
      "Epoch 531/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8180 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00531: mean_squared_error did not improve from 0.00905\n",
      "Epoch 532/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4144 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00532: mean_squared_error did not improve from 0.00905\n",
      "Epoch 533/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8731 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 00533: mean_squared_error did not improve from 0.00905\n",
      "Epoch 534/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4209 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00534: mean_squared_error did not improve from 0.00905\n",
      "Epoch 535/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2363 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00535: mean_squared_error did not improve from 0.00905\n",
      "Epoch 536/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7558 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00536: mean_squared_error did not improve from 0.00905\n",
      "Epoch 537/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9417 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00537: mean_squared_error did not improve from 0.00905\n",
      "Epoch 538/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7240 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00538: mean_squared_error did not improve from 0.00905\n",
      "Epoch 539/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5075 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00539: mean_squared_error did not improve from 0.00905\n",
      "Epoch 540/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7123 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00540: mean_squared_error did not improve from 0.00905\n",
      "Epoch 541/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8476 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00541: mean_squared_error did not improve from 0.00905\n",
      "Epoch 542/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5844 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00542: mean_squared_error did not improve from 0.00905\n",
      "Epoch 543/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9301 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00543: mean_squared_error did not improve from 0.00905\n",
      "Epoch 544/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.5994 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00544: mean_squared_error did not improve from 0.00905\n",
      "Epoch 545/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6759 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00545: mean_squared_error did not improve from 0.00905\n",
      "Epoch 546/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6886 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00546: mean_squared_error did not improve from 0.00905\n",
      "Epoch 547/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6914 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00547: mean_squared_error did not improve from 0.00905\n",
      "Epoch 548/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6076 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00548: mean_squared_error did not improve from 0.00905\n",
      "Epoch 549/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4407 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00549: mean_squared_error did not improve from 0.00905\n",
      "Epoch 550/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2849 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00550: mean_squared_error improved from 0.00905 to 0.00899, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 551/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4119 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00551: mean_squared_error did not improve from 0.00899\n",
      "Epoch 552/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4873 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00552: mean_squared_error did not improve from 0.00899\n",
      "Epoch 553/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6451 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00553: mean_squared_error did not improve from 0.00899\n",
      "Epoch 554/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7357 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00554: mean_squared_error did not improve from 0.00899\n",
      "Epoch 555/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9625 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00555: mean_squared_error did not improve from 0.00899\n",
      "Epoch 556/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4035 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00556: mean_squared_error did not improve from 0.00899\n",
      "Epoch 557/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2769 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00557: mean_squared_error did not improve from 0.00899\n",
      "Epoch 558/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3772 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00558: mean_squared_error did not improve from 0.00899\n",
      "Epoch 559/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6505 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00559: mean_squared_error did not improve from 0.00899\n",
      "Epoch 560/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6262 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00560: mean_squared_error did not improve from 0.00899\n",
      "Epoch 561/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4923 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00561: mean_squared_error did not improve from 0.00899\n",
      "Epoch 562/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0935 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00562: mean_squared_error did not improve from 0.00899\n",
      "Epoch 563/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5420 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00563: mean_squared_error did not improve from 0.00899\n",
      "Epoch 564/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4135 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00564: mean_squared_error did not improve from 0.00899\n",
      "Epoch 565/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1956 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00565: mean_squared_error did not improve from 0.00899\n",
      "Epoch 566/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4353 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00566: mean_squared_error did not improve from 0.00899\n",
      "Epoch 567/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5523 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00567: mean_squared_error did not improve from 0.00899\n",
      "Epoch 568/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1334 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00568: mean_squared_error did not improve from 0.00899\n",
      "Epoch 569/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5493 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00569: mean_squared_error did not improve from 0.00899\n",
      "Epoch 570/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2638 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00570: mean_squared_error did not improve from 0.00899\n",
      "Epoch 571/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1513 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00571: mean_squared_error did not improve from 0.00899\n",
      "Epoch 572/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5304 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00572: mean_squared_error did not improve from 0.00899\n",
      "Epoch 573/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5156 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00573: mean_squared_error did not improve from 0.00899\n",
      "Epoch 574/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3922 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00574: mean_squared_error did not improve from 0.00899\n",
      "Epoch 575/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3199 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00575: mean_squared_error did not improve from 0.00899\n",
      "Epoch 576/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.2768 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00576: mean_squared_error did not improve from 0.00899\n",
      "Epoch 577/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5929 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00577: mean_squared_error did not improve from 0.00899\n",
      "Epoch 578/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5263 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00578: mean_squared_error did not improve from 0.00899\n",
      "Epoch 579/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1536 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00579: mean_squared_error did not improve from 0.00899\n",
      "Epoch 580/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.2237 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00580: mean_squared_error did not improve from 0.00899\n",
      "Epoch 581/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0492 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00581: mean_squared_error did not improve from 0.00899\n",
      "Epoch 582/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5106 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00582: mean_squared_error did not improve from 0.00899\n",
      "Epoch 583/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.9348 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00583: mean_squared_error did not improve from 0.00899\n",
      "Epoch 584/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.0469 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00584: mean_squared_error did not improve from 0.00899\n",
      "Epoch 585/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.7630 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00585: mean_squared_error did not improve from 0.00899\n",
      "Epoch 586/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.4814 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 00586: mean_squared_error did not improve from 0.00899\n",
      "Epoch 587/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7922 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00587: mean_squared_error did not improve from 0.00899\n",
      "Epoch 588/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.4652 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00588: mean_squared_error did not improve from 0.00899\n",
      "Epoch 589/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.7163 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00589: mean_squared_error did not improve from 0.00899\n",
      "Epoch 590/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.6320 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00590: mean_squared_error did not improve from 0.00899\n",
      "Epoch 591/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3906 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00591: mean_squared_error did not improve from 0.00899\n",
      "Epoch 592/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6377 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00592: mean_squared_error did not improve from 0.00899\n",
      "Epoch 593/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3745 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00593: mean_squared_error did not improve from 0.00899\n",
      "Epoch 594/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1863 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00594: mean_squared_error did not improve from 0.00899\n",
      "Epoch 595/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3063 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00595: mean_squared_error did not improve from 0.00899\n",
      "Epoch 596/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4242 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00596: mean_squared_error did not improve from 0.00899\n",
      "Epoch 597/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7187 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00597: mean_squared_error did not improve from 0.00899\n",
      "Epoch 598/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3429 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00598: mean_squared_error did not improve from 0.00899\n",
      "Epoch 599/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3506 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00599: mean_squared_error did not improve from 0.00899\n",
      "Epoch 600/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7565 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00600: mean_squared_error did not improve from 0.00899\n",
      "Epoch 601/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6934 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00601: mean_squared_error did not improve from 0.00899\n",
      "Epoch 602/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7212 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00602: mean_squared_error did not improve from 0.00899\n",
      "Epoch 603/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1559 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00603: mean_squared_error improved from 0.00899 to 0.00885, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 604/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5647 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00604: mean_squared_error did not improve from 0.00885\n",
      "Epoch 605/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4473 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00605: mean_squared_error did not improve from 0.00885\n",
      "Epoch 606/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1634 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00606: mean_squared_error improved from 0.00885 to 0.00872, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 607/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4185 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00607: mean_squared_error did not improve from 0.00872\n",
      "Epoch 608/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3278 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00608: mean_squared_error did not improve from 0.00872\n",
      "Epoch 609/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2434 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00609: mean_squared_error did not improve from 0.00872\n",
      "Epoch 610/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3905 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00610: mean_squared_error did not improve from 0.00872\n",
      "Epoch 611/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2991 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00611: mean_squared_error did not improve from 0.00872\n",
      "Epoch 612/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1334 - mean_squared_error: 0.0092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00612: mean_squared_error did not improve from 0.00872\n",
      "Epoch 613/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4778 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00613: mean_squared_error did not improve from 0.00872\n",
      "Epoch 614/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5162 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00614: mean_squared_error did not improve from 0.00872\n",
      "Epoch 615/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5937 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00615: mean_squared_error did not improve from 0.00872\n",
      "Epoch 616/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0010 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00616: mean_squared_error did not improve from 0.00872\n",
      "Epoch 617/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5402 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00617: mean_squared_error did not improve from 0.00872\n",
      "Epoch 618/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1687 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00618: mean_squared_error did not improve from 0.00872\n",
      "Epoch 619/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8814 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00619: mean_squared_error improved from 0.00872 to 0.00865, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 620/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0612 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00620: mean_squared_error did not improve from 0.00865\n",
      "Epoch 621/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4737 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00621: mean_squared_error did not improve from 0.00865\n",
      "Epoch 622/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7652 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00622: mean_squared_error did not improve from 0.00865\n",
      "Epoch 623/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3010 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00623: mean_squared_error did not improve from 0.00865\n",
      "Epoch 624/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0971 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00624: mean_squared_error did not improve from 0.00865\n",
      "Epoch 625/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.0003 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00625: mean_squared_error did not improve from 0.00865\n",
      "Epoch 626/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9888 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00626: mean_squared_error did not improve from 0.00865\n",
      "Epoch 627/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0250 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00627: mean_squared_error did not improve from 0.00865\n",
      "Epoch 628/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9687 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00628: mean_squared_error improved from 0.00865 to 0.00858, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 629/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4219 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00629: mean_squared_error did not improve from 0.00858\n",
      "Epoch 630/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8955 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00630: mean_squared_error improved from 0.00858 to 0.00833, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 631/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4127 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00631: mean_squared_error did not improve from 0.00833\n",
      "Epoch 632/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4221 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00632: mean_squared_error did not improve from 0.00833\n",
      "Epoch 633/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4116 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00633: mean_squared_error did not improve from 0.00833\n",
      "Epoch 634/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2441 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00634: mean_squared_error did not improve from 0.00833\n",
      "Epoch 635/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1334 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00635: mean_squared_error did not improve from 0.00833\n",
      "Epoch 636/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3313 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00636: mean_squared_error did not improve from 0.00833\n",
      "Epoch 637/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5957 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00637: mean_squared_error did not improve from 0.00833\n",
      "Epoch 638/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4575 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00638: mean_squared_error did not improve from 0.00833\n",
      "Epoch 639/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7059 - mean_squared_error: 0.0115\n",
      "\n",
      "Epoch 00639: mean_squared_error did not improve from 0.00833\n",
      "Epoch 640/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2082 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00640: mean_squared_error did not improve from 0.00833\n",
      "Epoch 641/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2547 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00641: mean_squared_error did not improve from 0.00833\n",
      "Epoch 642/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1710 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00642: mean_squared_error did not improve from 0.00833\n",
      "Epoch 643/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3100 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00643: mean_squared_error did not improve from 0.00833\n",
      "Epoch 644/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.0714 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00644: mean_squared_error did not improve from 0.00833\n",
      "Epoch 645/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.2960 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00645: mean_squared_error did not improve from 0.00833\n",
      "Epoch 646/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1241 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00646: mean_squared_error did not improve from 0.00833\n",
      "Epoch 647/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2639 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00647: mean_squared_error did not improve from 0.00833\n",
      "Epoch 648/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7215 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00648: mean_squared_error did not improve from 0.00833\n",
      "Epoch 649/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1478 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00649: mean_squared_error did not improve from 0.00833\n",
      "Epoch 650/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0211 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00650: mean_squared_error did not improve from 0.00833\n",
      "Epoch 651/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5054 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00651: mean_squared_error did not improve from 0.00833\n",
      "Epoch 652/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5007 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00652: mean_squared_error did not improve from 0.00833\n",
      "Epoch 653/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0787 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00653: mean_squared_error did not improve from 0.00833\n",
      "Epoch 654/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4775 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00654: mean_squared_error did not improve from 0.00833\n",
      "Epoch 655/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9923 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00655: mean_squared_error did not improve from 0.00833\n",
      "Epoch 656/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2162 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00656: mean_squared_error did not improve from 0.00833\n",
      "Epoch 657/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3575 - mean_squared_error: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00657: mean_squared_error did not improve from 0.00833\n",
      "Epoch 658/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8737 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00658: mean_squared_error did not improve from 0.00833\n",
      "Epoch 659/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4070 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00659: mean_squared_error did not improve from 0.00833\n",
      "Epoch 660/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0448 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00660: mean_squared_error did not improve from 0.00833\n",
      "Epoch 661/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1141 - mean_squared_error: 0.0134\n",
      "\n",
      "Epoch 00661: mean_squared_error did not improve from 0.00833\n",
      "Epoch 662/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6866 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00662: mean_squared_error did not improve from 0.00833\n",
      "Epoch 663/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1987 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00663: mean_squared_error did not improve from 0.00833\n",
      "Epoch 664/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5642 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00664: mean_squared_error did not improve from 0.00833\n",
      "Epoch 665/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4693 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00665: mean_squared_error did not improve from 0.00833\n",
      "Epoch 666/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5303 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00666: mean_squared_error did not improve from 0.00833\n",
      "Epoch 667/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0498 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00667: mean_squared_error did not improve from 0.00833\n",
      "Epoch 668/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0688 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00668: mean_squared_error did not improve from 0.00833\n",
      "Epoch 669/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1827 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00669: mean_squared_error did not improve from 0.00833\n",
      "Epoch 670/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 9.3051 - mean_squared_error: 0.0178\n",
      "\n",
      "Epoch 00670: mean_squared_error did not improve from 0.00833\n",
      "Epoch 671/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4210 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00671: mean_squared_error did not improve from 0.00833\n",
      "Epoch 672/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 8.0185 - mean_squared_error: 0.0123\n",
      "\n",
      "Epoch 00672: mean_squared_error did not improve from 0.00833\n",
      "Epoch 673/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8041 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00673: mean_squared_error did not improve from 0.00833\n",
      "Epoch 674/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6326 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00674: mean_squared_error did not improve from 0.00833\n",
      "Epoch 675/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 7.3482 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00675: mean_squared_error did not improve from 0.00833\n",
      "Epoch 676/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.4702 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00676: mean_squared_error did not improve from 0.00833\n",
      "Epoch 677/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.7373 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00677: mean_squared_error did not improve from 0.00833\n",
      "Epoch 678/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.1982 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00678: mean_squared_error did not improve from 0.00833\n",
      "Epoch 679/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.6212 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00679: mean_squared_error did not improve from 0.00833\n",
      "Epoch 680/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.6306 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00680: mean_squared_error did not improve from 0.00833\n",
      "Epoch 681/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.8628 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00681: mean_squared_error did not improve from 0.00833\n",
      "Epoch 682/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.1491 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00682: mean_squared_error did not improve from 0.00833\n",
      "Epoch 683/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.4135 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00683: mean_squared_error did not improve from 0.00833\n",
      "Epoch 684/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.5348 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00684: mean_squared_error did not improve from 0.00833\n",
      "Epoch 685/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.3356 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00685: mean_squared_error did not improve from 0.00833\n",
      "Epoch 686/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.4339 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00686: mean_squared_error did not improve from 0.00833\n",
      "Epoch 687/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2913 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00687: mean_squared_error did not improve from 0.00833\n",
      "Epoch 688/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.8102 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 00688: mean_squared_error did not improve from 0.00833\n",
      "Epoch 689/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9859 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00689: mean_squared_error did not improve from 0.00833\n",
      "Epoch 690/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1249 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00690: mean_squared_error did not improve from 0.00833\n",
      "Epoch 691/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.0594 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00691: mean_squared_error did not improve from 0.00833\n",
      "Epoch 692/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1335 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00692: mean_squared_error did not improve from 0.00833\n",
      "Epoch 693/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9427 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00693: mean_squared_error did not improve from 0.00833\n",
      "Epoch 694/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.1787 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00694: mean_squared_error did not improve from 0.00833\n",
      "Epoch 695/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7332 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00695: mean_squared_error did not improve from 0.00833\n",
      "Epoch 696/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9176 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00696: mean_squared_error did not improve from 0.00833\n",
      "Epoch 697/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.3843 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 00697: mean_squared_error did not improve from 0.00833\n",
      "Epoch 698/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.7490 - mean_squared_error: 0.0126\n",
      "\n",
      "Epoch 00698: mean_squared_error did not improve from 0.00833\n",
      "Epoch 699/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.9733 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00699: mean_squared_error did not improve from 0.00833\n",
      "Epoch 700/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0835 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00700: mean_squared_error did not improve from 0.00833\n",
      "Epoch 701/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2847 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00701: mean_squared_error did not improve from 0.00833\n",
      "Epoch 702/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9049 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00702: mean_squared_error did not improve from 0.00833\n",
      "Epoch 703/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0242 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00703: mean_squared_error did not improve from 0.00833\n",
      "Epoch 704/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1553 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00704: mean_squared_error did not improve from 0.00833\n",
      "Epoch 705/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1201 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00705: mean_squared_error did not improve from 0.00833\n",
      "Epoch 706/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9486 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00706: mean_squared_error did not improve from 0.00833\n",
      "Epoch 707/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2807 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00707: mean_squared_error did not improve from 0.00833\n",
      "Epoch 708/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0929 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00708: mean_squared_error did not improve from 0.00833\n",
      "Epoch 709/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8638 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00709: mean_squared_error did not improve from 0.00833\n",
      "Epoch 710/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8264 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00710: mean_squared_error did not improve from 0.00833\n",
      "Epoch 711/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.3172 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00711: mean_squared_error did not improve from 0.00833\n",
      "Epoch 712/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8166 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00712: mean_squared_error did not improve from 0.00833\n",
      "Epoch 713/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1333 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00713: mean_squared_error did not improve from 0.00833\n",
      "Epoch 714/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8260 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00714: mean_squared_error did not improve from 0.00833\n",
      "Epoch 715/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8010 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00715: mean_squared_error did not improve from 0.00833\n",
      "Epoch 716/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9577 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00716: mean_squared_error did not improve from 0.00833\n",
      "Epoch 717/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1233 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00717: mean_squared_error did not improve from 0.00833\n",
      "Epoch 718/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7921 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00718: mean_squared_error did not improve from 0.00833\n",
      "Epoch 719/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6623 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00719: mean_squared_error did not improve from 0.00833\n",
      "Epoch 720/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5819 - mean_squared_error: 0.0122\n",
      "\n",
      "Epoch 00720: mean_squared_error did not improve from 0.00833\n",
      "Epoch 721/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.7445 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00721: mean_squared_error did not improve from 0.00833\n",
      "Epoch 722/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.9547 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00722: mean_squared_error did not improve from 0.00833\n",
      "Epoch 723/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5998 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00723: mean_squared_error did not improve from 0.00833\n",
      "Epoch 724/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0413 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00724: mean_squared_error did not improve from 0.00833\n",
      "Epoch 725/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8552 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00725: mean_squared_error did not improve from 0.00833\n",
      "Epoch 726/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9099 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00726: mean_squared_error did not improve from 0.00833\n",
      "Epoch 727/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2695 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00727: mean_squared_error did not improve from 0.00833\n",
      "Epoch 728/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9728 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00728: mean_squared_error did not improve from 0.00833\n",
      "Epoch 729/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.9548 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00729: mean_squared_error did not improve from 0.00833\n",
      "Epoch 730/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8730 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00730: mean_squared_error did not improve from 0.00833\n",
      "Epoch 731/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6508 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00731: mean_squared_error improved from 0.00833 to 0.00809, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 732/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7638 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00732: mean_squared_error did not improve from 0.00809\n",
      "Epoch 733/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9284 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00733: mean_squared_error did not improve from 0.00809\n",
      "Epoch 734/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.9335 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00734: mean_squared_error did not improve from 0.00809\n",
      "Epoch 735/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6485 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00735: mean_squared_error did not improve from 0.00809\n",
      "Epoch 736/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.0693 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00736: mean_squared_error did not improve from 0.00809\n",
      "Epoch 737/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.1931 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00737: mean_squared_error did not improve from 0.00809\n",
      "Epoch 738/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7755 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00738: mean_squared_error did not improve from 0.00809\n",
      "Epoch 739/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.8032 - mean_squared_error: 0.0127\n",
      "\n",
      "Epoch 00739: mean_squared_error did not improve from 0.00809\n",
      "Epoch 740/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.8440 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00740: mean_squared_error did not improve from 0.00809\n",
      "Epoch 741/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9591 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00741: mean_squared_error did not improve from 0.00809\n",
      "Epoch 742/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0084 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00742: mean_squared_error did not improve from 0.00809\n",
      "Epoch 743/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.6706 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00743: mean_squared_error did not improve from 0.00809\n",
      "Epoch 744/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0936 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00744: mean_squared_error did not improve from 0.00809\n",
      "Epoch 745/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0512 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00745: mean_squared_error did not improve from 0.00809\n",
      "Epoch 746/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9966 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00746: mean_squared_error did not improve from 0.00809\n",
      "Epoch 747/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8686 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00747: mean_squared_error did not improve from 0.00809\n",
      "Epoch 748/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.8889 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00748: mean_squared_error did not improve from 0.00809\n",
      "Epoch 749/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0586 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00749: mean_squared_error did not improve from 0.00809\n",
      "Epoch 750/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7420 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00750: mean_squared_error did not improve from 0.00809\n",
      "Epoch 751/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7753 - mean_squared_error: 0.0091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00751: mean_squared_error did not improve from 0.00809\n",
      "Epoch 752/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8089 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00752: mean_squared_error did not improve from 0.00809\n",
      "Epoch 753/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7240 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00753: mean_squared_error did not improve from 0.00809\n",
      "Epoch 754/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0385 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00754: mean_squared_error did not improve from 0.00809\n",
      "Epoch 755/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5669 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00755: mean_squared_error did not improve from 0.00809\n",
      "Epoch 756/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.7348 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00756: mean_squared_error did not improve from 0.00809\n",
      "Epoch 757/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6222 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00757: mean_squared_error did not improve from 0.00809\n",
      "Epoch 758/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.6684 - mean_squared_error: 0.0129\n",
      "\n",
      "Epoch 00758: mean_squared_error did not improve from 0.00809\n",
      "Epoch 759/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7355 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00759: mean_squared_error did not improve from 0.00809\n",
      "Epoch 760/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9535 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00760: mean_squared_error did not improve from 0.00809\n",
      "Epoch 761/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.5714 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 00761: mean_squared_error did not improve from 0.00809\n",
      "Epoch 762/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1261 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00762: mean_squared_error did not improve from 0.00809\n",
      "Epoch 763/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9293 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00763: mean_squared_error did not improve from 0.00809\n",
      "Epoch 764/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8906 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00764: mean_squared_error did not improve from 0.00809\n",
      "Epoch 765/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1103 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00765: mean_squared_error did not improve from 0.00809\n",
      "Epoch 766/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.1307 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00766: mean_squared_error did not improve from 0.00809\n",
      "Epoch 767/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3667 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00767: mean_squared_error did not improve from 0.00809\n",
      "Epoch 768/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6683 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00768: mean_squared_error improved from 0.00809 to 0.00806, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 769/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9105 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00769: mean_squared_error did not improve from 0.00806\n",
      "Epoch 770/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6193 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00770: mean_squared_error did not improve from 0.00806\n",
      "Epoch 771/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0807 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00771: mean_squared_error did not improve from 0.00806\n",
      "Epoch 772/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.8440 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00772: mean_squared_error did not improve from 0.00806\n",
      "Epoch 773/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.7663 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00773: mean_squared_error did not improve from 0.00806\n",
      "Epoch 774/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.9612 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00774: mean_squared_error did not improve from 0.00806\n",
      "Epoch 775/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.7469 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00775: mean_squared_error did not improve from 0.00806\n",
      "Epoch 776/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0844 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00776: mean_squared_error did not improve from 0.00806\n",
      "Epoch 777/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4999 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00777: mean_squared_error did not improve from 0.00806\n",
      "Epoch 778/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.7822 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00778: mean_squared_error did not improve from 0.00806\n",
      "Epoch 779/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1393 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00779: mean_squared_error did not improve from 0.00806\n",
      "Epoch 780/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7669 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00780: mean_squared_error did not improve from 0.00806\n",
      "Epoch 781/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0257 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00781: mean_squared_error did not improve from 0.00806\n",
      "Epoch 782/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9202 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00782: mean_squared_error did not improve from 0.00806\n",
      "Epoch 783/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5270 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00783: mean_squared_error did not improve from 0.00806\n",
      "Epoch 784/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1074 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00784: mean_squared_error did not improve from 0.00806\n",
      "Epoch 785/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1132 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00785: mean_squared_error did not improve from 0.00806\n",
      "Epoch 786/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0441 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00786: mean_squared_error did not improve from 0.00806\n",
      "Epoch 787/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8255 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00787: mean_squared_error did not improve from 0.00806\n",
      "Epoch 788/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9659 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00788: mean_squared_error did not improve from 0.00806\n",
      "Epoch 789/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7889 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00789: mean_squared_error did not improve from 0.00806\n",
      "Epoch 790/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.8541 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00790: mean_squared_error did not improve from 0.00806\n",
      "Epoch 791/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 7.0835 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00791: mean_squared_error did not improve from 0.00806\n",
      "Epoch 792/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7899 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00792: mean_squared_error did not improve from 0.00806\n",
      "Epoch 793/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.6189 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00793: mean_squared_error did not improve from 0.00806\n",
      "Epoch 794/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.6024 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00794: mean_squared_error did not improve from 0.00806\n",
      "Epoch 795/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9686 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00795: mean_squared_error did not improve from 0.00806\n",
      "Epoch 796/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.8063 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00796: mean_squared_error did not improve from 0.00806\n",
      "Epoch 797/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.9636 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00797: mean_squared_error did not improve from 0.00806\n",
      "Epoch 798/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 11ms/step - loss: 6.5864 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00798: mean_squared_error did not improve from 0.00806\n",
      "Epoch 799/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5968 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00799: mean_squared_error did not improve from 0.00806\n",
      "Epoch 800/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.6170 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00800: mean_squared_error did not improve from 0.00806\n",
      "Epoch 801/2000\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 6.5283 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00801: mean_squared_error did not improve from 0.00806\n",
      "Epoch 802/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 7.1277 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00802: mean_squared_error did not improve from 0.00806\n",
      "Epoch 803/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.7040 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00803: mean_squared_error did not improve from 0.00806\n",
      "Epoch 804/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.6919 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00804: mean_squared_error did not improve from 0.00806\n",
      "Epoch 805/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.6507 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00805: mean_squared_error did not improve from 0.00806\n",
      "Epoch 806/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.6121 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00806: mean_squared_error did not improve from 0.00806\n",
      "Epoch 807/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.7030 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00807: mean_squared_error did not improve from 0.00806\n",
      "Epoch 808/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.9996 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00808: mean_squared_error did not improve from 0.00806\n",
      "Epoch 809/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.5447 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00809: mean_squared_error did not improve from 0.00806\n",
      "Epoch 810/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.4460 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00810: mean_squared_error did not improve from 0.00806\n",
      "Epoch 811/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.7351 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00811: mean_squared_error did not improve from 0.00806\n",
      "Epoch 812/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.7726 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00812: mean_squared_error did not improve from 0.00806\n",
      "Epoch 813/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5245 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00813: mean_squared_error did not improve from 0.00806\n",
      "Epoch 814/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.5244 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00814: mean_squared_error did not improve from 0.00806\n",
      "Epoch 815/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.4487 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00815: mean_squared_error did not improve from 0.00806\n",
      "Epoch 816/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.3614 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00816: mean_squared_error did not improve from 0.00806\n",
      "Epoch 817/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5958 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00817: mean_squared_error did not improve from 0.00806\n",
      "Epoch 818/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8674 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00818: mean_squared_error did not improve from 0.00806\n",
      "Epoch 819/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6298 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00819: mean_squared_error did not improve from 0.00806\n",
      "Epoch 820/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.6159 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00820: mean_squared_error did not improve from 0.00806\n",
      "Epoch 821/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9891 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00821: mean_squared_error did not improve from 0.00806\n",
      "Epoch 822/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6905 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00822: mean_squared_error did not improve from 0.00806\n",
      "Epoch 823/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4716 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00823: mean_squared_error did not improve from 0.00806\n",
      "Epoch 824/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9116 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00824: mean_squared_error did not improve from 0.00806\n",
      "Epoch 825/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5347 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00825: mean_squared_error did not improve from 0.00806\n",
      "Epoch 826/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4702 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00826: mean_squared_error did not improve from 0.00806\n",
      "Epoch 827/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7877 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00827: mean_squared_error did not improve from 0.00806\n",
      "Epoch 828/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.4513 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00828: mean_squared_error did not improve from 0.00806\n",
      "Epoch 829/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 7.0330 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00829: mean_squared_error did not improve from 0.00806\n",
      "Epoch 830/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.5667 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00830: mean_squared_error did not improve from 0.00806\n",
      "Epoch 831/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5095 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00831: mean_squared_error did not improve from 0.00806\n",
      "Epoch 832/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.9813 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00832: mean_squared_error did not improve from 0.00806\n",
      "Epoch 833/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.4297 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00833: mean_squared_error did not improve from 0.00806\n",
      "Epoch 834/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.5327 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00834: mean_squared_error did not improve from 0.00806\n",
      "Epoch 835/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.7702 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00835: mean_squared_error did not improve from 0.00806\n",
      "Epoch 836/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0576 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 00836: mean_squared_error did not improve from 0.00806\n",
      "Epoch 837/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.8557 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00837: mean_squared_error did not improve from 0.00806\n",
      "Epoch 838/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.9536 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00838: mean_squared_error did not improve from 0.00806\n",
      "Epoch 839/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 7.2429 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00839: mean_squared_error did not improve from 0.00806\n",
      "Epoch 840/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.7676 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00840: mean_squared_error did not improve from 0.00806\n",
      "Epoch 841/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.8550 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00841: mean_squared_error did not improve from 0.00806\n",
      "Epoch 842/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.7456 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00842: mean_squared_error did not improve from 0.00806\n",
      "Epoch 843/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.1085 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00843: mean_squared_error did not improve from 0.00806\n",
      "Epoch 844/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.8408 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00844: mean_squared_error did not improve from 0.00806\n",
      "Epoch 845/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 14ms/step - loss: 6.5669 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00845: mean_squared_error did not improve from 0.00806\n",
      "Epoch 846/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.5961 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00846: mean_squared_error did not improve from 0.00806\n",
      "Epoch 847/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 6.6951 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00847: mean_squared_error did not improve from 0.00806\n",
      "Epoch 848/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 7.3288 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 00848: mean_squared_error did not improve from 0.00806\n",
      "Epoch 849/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.7751 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00849: mean_squared_error did not improve from 0.00806\n",
      "Epoch 850/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.8479 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00850: mean_squared_error did not improve from 0.00806\n",
      "Epoch 851/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 6.7212 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00851: mean_squared_error did not improve from 0.00806\n",
      "Epoch 852/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.5994 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00852: mean_squared_error did not improve from 0.00806\n",
      "Epoch 853/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.9258 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00853: mean_squared_error did not improve from 0.00806\n",
      "Epoch 854/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.7461 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00854: mean_squared_error did not improve from 0.00806\n",
      "Epoch 855/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.7050 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00855: mean_squared_error did not improve from 0.00806\n",
      "Epoch 856/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.7680 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00856: mean_squared_error did not improve from 0.00806\n",
      "Epoch 857/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.7698 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00857: mean_squared_error did not improve from 0.00806\n",
      "Epoch 858/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.7503 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00858: mean_squared_error did not improve from 0.00806\n",
      "Epoch 859/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.5197 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00859: mean_squared_error did not improve from 0.00806\n",
      "Epoch 860/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.6473 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00860: mean_squared_error did not improve from 0.00806\n",
      "Epoch 861/2000\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 6.9690 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 00861: mean_squared_error did not improve from 0.00806\n",
      "Epoch 862/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.5392 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00862: mean_squared_error did not improve from 0.00806\n",
      "Epoch 863/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.4541 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00863: mean_squared_error did not improve from 0.00806\n",
      "Epoch 864/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.6456 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00864: mean_squared_error did not improve from 0.00806\n",
      "Epoch 865/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.4733 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00865: mean_squared_error did not improve from 0.00806\n",
      "Epoch 866/2000\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 7.1495 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 00866: mean_squared_error did not improve from 0.00806\n",
      "Epoch 867/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 6.6632 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00867: mean_squared_error did not improve from 0.00806\n",
      "Epoch 868/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 6.5308 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00868: mean_squared_error did not improve from 0.00806\n",
      "Epoch 869/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.5947 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00869: mean_squared_error did not improve from 0.00806\n",
      "Epoch 870/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 7.1272 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 00870: mean_squared_error did not improve from 0.00806\n",
      "Epoch 871/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 6.6073 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00871: mean_squared_error did not improve from 0.00806\n",
      "Epoch 872/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.4430 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00872: mean_squared_error did not improve from 0.00806\n",
      "Epoch 873/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.5005 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00873: mean_squared_error did not improve from 0.00806\n",
      "Epoch 874/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.9080 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 00874: mean_squared_error did not improve from 0.00806\n",
      "Epoch 875/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.3975 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00875: mean_squared_error did not improve from 0.00806\n",
      "Epoch 876/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.4614 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00876: mean_squared_error did not improve from 0.00806\n",
      "Epoch 877/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.4507 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00877: mean_squared_error did not improve from 0.00806\n",
      "Epoch 878/2000\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 6.8260 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00878: mean_squared_error did not improve from 0.00806\n",
      "Epoch 879/2000\n",
      "28/28 [==============================] - 1s 20ms/step - loss: 6.2131 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 00879: mean_squared_error improved from 0.00806 to 0.00791, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 880/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.6233 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00880: mean_squared_error did not improve from 0.00791\n",
      "Epoch 881/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.4120 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00881: mean_squared_error did not improve from 0.00791\n",
      "Epoch 882/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.3756 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00882: mean_squared_error did not improve from 0.00791\n",
      "Epoch 883/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.6995 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 00883: mean_squared_error did not improve from 0.00791\n",
      "Epoch 884/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.3876 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00884: mean_squared_error did not improve from 0.00791\n",
      "Epoch 885/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.6464 - mean_squared_error: 0.0134\n",
      "\n",
      "Epoch 00885: mean_squared_error did not improve from 0.00791\n",
      "Epoch 886/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5098 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00886: mean_squared_error did not improve from 0.00791\n",
      "Epoch 887/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3653 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00887: mean_squared_error did not improve from 0.00791\n",
      "Epoch 888/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5900 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00888: mean_squared_error did not improve from 0.00791\n",
      "Epoch 889/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4953 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00889: mean_squared_error did not improve from 0.00791\n",
      "Epoch 890/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5209 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00890: mean_squared_error did not improve from 0.00791\n",
      "Epoch 891/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3411 - mean_squared_error: 0.0081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00891: mean_squared_error did not improve from 0.00791\n",
      "Epoch 892/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6664 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00892: mean_squared_error did not improve from 0.00791\n",
      "Epoch 893/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 6.3591 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00893: mean_squared_error did not improve from 0.00791\n",
      "Epoch 894/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.4553 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00894: mean_squared_error did not improve from 0.00791\n",
      "Epoch 895/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.6425 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00895: mean_squared_error did not improve from 0.00791\n",
      "Epoch 896/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 6.4705 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00896: mean_squared_error did not improve from 0.00791\n",
      "Epoch 897/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.6602 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00897: mean_squared_error did not improve from 0.00791\n",
      "Epoch 898/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.4154 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00898: mean_squared_error did not improve from 0.00791\n",
      "Epoch 899/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.3384 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00899: mean_squared_error did not improve from 0.00791\n",
      "Epoch 900/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.7080 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00900: mean_squared_error did not improve from 0.00791\n",
      "Epoch 901/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.3288 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00901: mean_squared_error did not improve from 0.00791\n",
      "Epoch 902/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.8242 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 00902: mean_squared_error did not improve from 0.00791\n",
      "Epoch 903/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.3999 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00903: mean_squared_error did not improve from 0.00791\n",
      "Epoch 904/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.4421 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00904: mean_squared_error did not improve from 0.00791\n",
      "Epoch 905/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.6028 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00905: mean_squared_error did not improve from 0.00791\n",
      "Epoch 906/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.6056 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00906: mean_squared_error did not improve from 0.00791\n",
      "Epoch 907/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.3833 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00907: mean_squared_error did not improve from 0.00791\n",
      "Epoch 908/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.3497 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00908: mean_squared_error did not improve from 0.00791\n",
      "Epoch 909/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.0971 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 00909: mean_squared_error improved from 0.00791 to 0.00782, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 910/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.4234 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00910: mean_squared_error did not improve from 0.00782\n",
      "Epoch 911/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.2783 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00911: mean_squared_error did not improve from 0.00782\n",
      "Epoch 912/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2729 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00912: mean_squared_error did not improve from 0.00782\n",
      "Epoch 913/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0502 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00913: mean_squared_error did not improve from 0.00782\n",
      "Epoch 914/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7304 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 00914: mean_squared_error did not improve from 0.00782\n",
      "Epoch 915/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2220 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00915: mean_squared_error did not improve from 0.00782\n",
      "Epoch 916/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.4309 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00916: mean_squared_error did not improve from 0.00782\n",
      "Epoch 917/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 8.1085 - mean_squared_error: 0.0154\n",
      "\n",
      "Epoch 00917: mean_squared_error did not improve from 0.00782\n",
      "Epoch 918/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6532 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 00918: mean_squared_error did not improve from 0.00782\n",
      "Epoch 919/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.5783 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00919: mean_squared_error did not improve from 0.00782\n",
      "Epoch 920/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3784 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00920: mean_squared_error did not improve from 0.00782\n",
      "Epoch 921/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 7.0478 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00921: mean_squared_error did not improve from 0.00782\n",
      "Epoch 922/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8225 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00922: mean_squared_error did not improve from 0.00782\n",
      "Epoch 923/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4652 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00923: mean_squared_error did not improve from 0.00782\n",
      "Epoch 924/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4889 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00924: mean_squared_error did not improve from 0.00782\n",
      "Epoch 925/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4955 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00925: mean_squared_error did not improve from 0.00782\n",
      "Epoch 926/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.8012 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00926: mean_squared_error did not improve from 0.00782\n",
      "Epoch 927/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.4248 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00927: mean_squared_error did not improve from 0.00782\n",
      "Epoch 928/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.5985 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00928: mean_squared_error did not improve from 0.00782\n",
      "Epoch 929/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.6465 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00929: mean_squared_error did not improve from 0.00782\n",
      "Epoch 930/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 6.5471 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00930: mean_squared_error did not improve from 0.00782\n",
      "Epoch 931/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.3327 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00931: mean_squared_error did not improve from 0.00782\n",
      "Epoch 932/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.4165 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00932: mean_squared_error did not improve from 0.00782\n",
      "Epoch 933/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.4234 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00933: mean_squared_error did not improve from 0.00782\n",
      "Epoch 934/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.9163 - mean_squared_error: 0.0110\n",
      "\n",
      "Epoch 00934: mean_squared_error did not improve from 0.00782\n",
      "Epoch 935/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.3728 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00935: mean_squared_error did not improve from 0.00782\n",
      "Epoch 936/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2712 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00936: mean_squared_error did not improve from 0.00782\n",
      "Epoch 937/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3484 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00937: mean_squared_error did not improve from 0.00782\n",
      "Epoch 938/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4188 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00938: mean_squared_error did not improve from 0.00782\n",
      "Epoch 939/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.4896 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00939: mean_squared_error did not improve from 0.00782\n",
      "Epoch 940/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.1865 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00940: mean_squared_error did not improve from 0.00782\n",
      "Epoch 941/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.7104 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 00941: mean_squared_error did not improve from 0.00782\n",
      "Epoch 942/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.0867 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00942: mean_squared_error did not improve from 0.00782\n",
      "Epoch 943/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.2262 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00943: mean_squared_error did not improve from 0.00782\n",
      "Epoch 944/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.2244 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00944: mean_squared_error did not improve from 0.00782\n",
      "Epoch 945/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.3046 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00945: mean_squared_error did not improve from 0.00782\n",
      "Epoch 946/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.0515 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00946: mean_squared_error did not improve from 0.00782\n",
      "Epoch 947/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.3748 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00947: mean_squared_error did not improve from 0.00782\n",
      "Epoch 948/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.2342 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00948: mean_squared_error did not improve from 0.00782\n",
      "Epoch 949/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.3888 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00949: mean_squared_error did not improve from 0.00782\n",
      "Epoch 950/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6225 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 00950: mean_squared_error did not improve from 0.00782\n",
      "Epoch 951/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6408 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00951: mean_squared_error did not improve from 0.00782\n",
      "Epoch 952/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.1490 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00952: mean_squared_error did not improve from 0.00782\n",
      "Epoch 953/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.2469 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00953: mean_squared_error did not improve from 0.00782\n",
      "Epoch 954/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3099 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00954: mean_squared_error did not improve from 0.00782\n",
      "Epoch 955/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1192 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00955: mean_squared_error did not improve from 0.00782\n",
      "Epoch 956/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.0669 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00956: mean_squared_error did not improve from 0.00782\n",
      "Epoch 957/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.3901 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00957: mean_squared_error did not improve from 0.00782\n",
      "Epoch 958/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1866 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00958: mean_squared_error did not improve from 0.00782\n",
      "Epoch 959/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4819 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00959: mean_squared_error did not improve from 0.00782\n",
      "Epoch 960/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.7909 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00960: mean_squared_error did not improve from 0.00782\n",
      "Epoch 961/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5290 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00961: mean_squared_error did not improve from 0.00782\n",
      "Epoch 962/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4481 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00962: mean_squared_error did not improve from 0.00782\n",
      "Epoch 963/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5902 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 00963: mean_squared_error did not improve from 0.00782\n",
      "Epoch 964/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7677 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 00964: mean_squared_error did not improve from 0.00782\n",
      "Epoch 965/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6165 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 00965: mean_squared_error did not improve from 0.00782\n",
      "Epoch 966/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.1385 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 00966: mean_squared_error did not improve from 0.00782\n",
      "Epoch 967/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4308 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00967: mean_squared_error did not improve from 0.00782\n",
      "Epoch 968/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4007 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00968: mean_squared_error did not improve from 0.00782\n",
      "Epoch 969/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3563 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 00969: mean_squared_error did not improve from 0.00782\n",
      "Epoch 970/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4086 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00970: mean_squared_error did not improve from 0.00782\n",
      "Epoch 971/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0426 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 00971: mean_squared_error did not improve from 0.00782\n",
      "Epoch 972/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4190 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00972: mean_squared_error did not improve from 0.00782\n",
      "Epoch 973/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4493 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00973: mean_squared_error did not improve from 0.00782\n",
      "Epoch 974/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4045 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00974: mean_squared_error did not improve from 0.00782\n",
      "Epoch 975/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2501 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00975: mean_squared_error did not improve from 0.00782\n",
      "Epoch 976/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.2620 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 00976: mean_squared_error did not improve from 0.00782\n",
      "Epoch 977/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1807 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 00977: mean_squared_error did not improve from 0.00782\n",
      "Epoch 978/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5589 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00978: mean_squared_error did not improve from 0.00782\n",
      "Epoch 979/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2064 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00979: mean_squared_error did not improve from 0.00782\n",
      "Epoch 980/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2171 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 00980: mean_squared_error did not improve from 0.00782\n",
      "Epoch 981/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4133 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00981: mean_squared_error did not improve from 0.00782\n",
      "Epoch 982/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3539 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 00982: mean_squared_error did not improve from 0.00782\n",
      "Epoch 983/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.0778 - mean_squared_error: 0.0117\n",
      "\n",
      "Epoch 00983: mean_squared_error did not improve from 0.00782\n",
      "Epoch 984/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3087 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 00984: mean_squared_error did not improve from 0.00782\n",
      "Epoch 985/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3484 - mean_squared_error: 0.0088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00985: mean_squared_error did not improve from 0.00782\n",
      "Epoch 986/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4308 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00986: mean_squared_error did not improve from 0.00782\n",
      "Epoch 987/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4184 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00987: mean_squared_error did not improve from 0.00782\n",
      "Epoch 988/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4405 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 00988: mean_squared_error did not improve from 0.00782\n",
      "Epoch 989/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2836 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 00989: mean_squared_error did not improve from 0.00782\n",
      "Epoch 990/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.3503 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 00990: mean_squared_error did not improve from 0.00782\n",
      "Epoch 991/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.4369 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 00991: mean_squared_error did not improve from 0.00782\n",
      "Epoch 992/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4715 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 00992: mean_squared_error did not improve from 0.00782\n",
      "Epoch 993/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4338 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 00993: mean_squared_error did not improve from 0.00782\n",
      "Epoch 994/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4822 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 00994: mean_squared_error did not improve from 0.00782\n",
      "Epoch 995/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3529 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 00995: mean_squared_error did not improve from 0.00782\n",
      "Epoch 996/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.2358 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 00996: mean_squared_error did not improve from 0.00782\n",
      "Epoch 997/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.1294 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 00997: mean_squared_error did not improve from 0.00782\n",
      "Epoch 998/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.1958 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 00998: mean_squared_error did not improve from 0.00782\n",
      "Epoch 999/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5385 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 00999: mean_squared_error did not improve from 0.00782\n",
      "Epoch 1000/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9043 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01000: mean_squared_error improved from 0.00782 to 0.00741, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1001/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.2370 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01001: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1002/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.0333 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01002: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1003/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7709 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 01003: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1004/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0009 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01004: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1005/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1782 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01005: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1006/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0736 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01006: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1007/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0588 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01007: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1008/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9833 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01008: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1009/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0063 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01009: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1010/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2289 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01010: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1011/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1335 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01011: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1012/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.7860 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 01012: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1013/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0721 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01013: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1014/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.6040 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01014: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1015/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1413 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01015: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1016/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2296 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01016: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1017/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.1197 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01017: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1018/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4094 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01018: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1019/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0229 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01019: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1020/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.1356 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01020: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1021/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3081 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01021: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1022/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1429 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01022: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1023/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2795 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01023: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1024/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1551 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01024: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1025/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5522 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 01025: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1026/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2515 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01026: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1027/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3342 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01027: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1028/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3240 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01028: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1029/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9105 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01029: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1030/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0929 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01030: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1031/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3001 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01031: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1032/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9891 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01032: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1033/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2406 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01033: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1034/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1736 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01034: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1035/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0733 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01035: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1036/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2352 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01036: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1037/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2106 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01037: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1038/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3166 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01038: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1039/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0077 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01039: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1040/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0544 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01040: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1041/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8685 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01041: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1042/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2017 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01042: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1043/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1275 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01043: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1044/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1344 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01044: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1045/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1805 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01045: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1046/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5962 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01046: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1047/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6225 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01047: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1048/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1848 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01048: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1049/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4630 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 01049: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1050/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4222 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01050: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1051/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1086 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01051: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1052/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3022 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01052: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1053/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1572 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01053: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1054/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1948 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01054: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1055/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0909 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01055: mean_squared_error did not improve from 0.00741\n",
      "Epoch 1056/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8896 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01056: mean_squared_error improved from 0.00741 to 0.00732, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1057/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2214 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01057: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1058/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1280 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01058: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1059/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0235 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01059: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1060/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2249 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01060: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1061/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1413 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01061: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1062/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8349 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01062: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1063/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9419 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01063: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1064/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8935 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01064: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1065/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9997 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01065: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1066/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5762 - mean_squared_error: 0.0108\n",
      "\n",
      "Epoch 01066: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1067/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8353 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01067: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1068/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1599 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01068: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1069/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0206 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01069: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1070/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0565 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01070: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1071/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0002 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01071: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1072/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8380 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01072: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1073/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8932 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01073: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1074/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8237 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01074: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1075/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0985 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01075: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1076/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.9097 - mean_squared_error: 0.0119\n",
      "\n",
      "Epoch 01076: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1077/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0059 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01077: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1078/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9639 - mean_squared_error: 0.0080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01078: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1079/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8858 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01079: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1080/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3615 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01080: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1081/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0664 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01081: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1082/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1603 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01082: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1083/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0567 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01083: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1084/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4704 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 01084: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1085/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 7.3580 - mean_squared_error: 0.0130\n",
      "\n",
      "Epoch 01085: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1086/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1013 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01086: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1087/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3126 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01087: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1088/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3363 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01088: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1089/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1153 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01089: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1090/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2370 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01090: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1091/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0461 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01091: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1092/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4169 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01092: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1093/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3367 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01093: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1094/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1602 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01094: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1095/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.0412 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01095: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1096/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.0982 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01096: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1097/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9723 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01097: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1098/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9912 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01098: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1099/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4786 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 01099: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1100/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8839 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01100: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1101/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.1506 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01101: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1102/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0916 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01102: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1103/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9049 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01103: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1104/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.8026 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01104: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1105/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7509 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01105: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1106/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5719 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01106: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1107/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9626 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01107: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1108/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7833 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01108: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1109/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7858 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01109: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1110/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.0833 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 01110: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1111/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0940 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 01111: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1112/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0368 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01112: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1113/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3927 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 01113: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1114/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9574 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01114: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1115/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7212 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01115: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1116/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9864 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01116: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1117/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1053 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01117: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1118/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1396 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 01118: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1119/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2113 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 01119: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1120/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8992 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01120: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1121/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9460 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01121: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1122/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8821 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01122: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1123/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5293 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 01123: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1124/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0987 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01124: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1125/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.0599 - mean_squared_error: 0.0090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01125: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1126/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8912 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01126: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1127/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9504 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01127: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1128/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 7.7929 - mean_squared_error: 0.0150\n",
      "\n",
      "Epoch 01128: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1129/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8662 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01129: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1130/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1323 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01130: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1131/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.9488 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01131: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1132/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9466 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01132: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1133/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.4811 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01133: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1134/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.2240 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01134: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1135/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8748 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01135: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1136/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.8988 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01136: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1137/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9788 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01137: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1138/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8463 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01138: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1139/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.1218 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01139: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1140/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7990 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01140: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1141/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9989 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01141: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1142/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0297 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01142: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1143/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.8785 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01143: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1144/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7765 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01144: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1145/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1985 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 01145: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1146/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7443 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01146: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1147/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.9910 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01147: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1148/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7986 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01148: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1149/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.7878 - mean_squared_error: 0.0120\n",
      "\n",
      "Epoch 01149: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1150/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.4720 - mean_squared_error: 0.0107\n",
      "\n",
      "Epoch 01150: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1151/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7557 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01151: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1152/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9947 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01152: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1153/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7837 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01153: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1154/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9280 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01154: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1155/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9251 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01155: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1156/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8423 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01156: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1157/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0233 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01157: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1158/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7828 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01158: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1159/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7925 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01159: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1160/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9940 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01160: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1161/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.5232 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 01161: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1162/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9034 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01162: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1163/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6668 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01163: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1164/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8081 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01164: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1165/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7939 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01165: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1166/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.2544 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 01166: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1167/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7927 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01167: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1168/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8512 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01168: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1169/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8540 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01169: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1170/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6521 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01170: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1171/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9246 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01171: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1172/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6715 - mean_squared_error: 0.0085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01172: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1173/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.3883 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 01173: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1174/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.7610 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01174: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1175/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.5021 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01175: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1176/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.8567 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01176: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1177/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.5478 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01177: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1178/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.6678 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01178: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1179/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.5619 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01179: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1180/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.5961 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01180: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1181/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.3958 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 01181: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1182/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.6656 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01182: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1183/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.8404 - mean_squared_error: 0.0128\n",
      "\n",
      "Epoch 01183: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1184/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5667 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01184: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1185/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.7169 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01185: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1186/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.9288 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01186: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1187/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8116 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01187: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1188/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.1526 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01188: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1189/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.9582 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01189: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1190/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7765 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01190: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1191/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.8153 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01191: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1192/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.0044 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01192: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1193/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8455 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01193: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1194/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8562 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01194: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1195/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.0332 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01195: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1196/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7534 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01196: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1197/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8018 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01197: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1198/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8974 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01198: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1199/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6308 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01199: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1200/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.6870 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01200: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1201/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8427 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01201: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1202/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.8634 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01202: mean_squared_error did not improve from 0.00732\n",
      "Epoch 1203/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4524 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01203: mean_squared_error improved from 0.00732 to 0.00708, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1204/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6924 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01204: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1205/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.0791 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01205: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1206/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7314 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01206: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1207/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0978 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01207: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1208/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4720 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01208: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1209/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9085 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01209: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1210/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6268 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01210: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1211/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4616 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01211: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1212/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5275 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01212: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1213/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6460 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01213: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1214/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4391 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01214: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1215/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8881 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01215: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1216/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6972 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01216: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1217/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.6619 - mean_squared_error: 0.0118\n",
      "\n",
      "Epoch 01217: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1218/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4175 - mean_squared_error: 0.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01218: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1219/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3281 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01219: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1220/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7486 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01220: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1221/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6524 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01221: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1222/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6737 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01222: mean_squared_error did not improve from 0.00708\n",
      "Epoch 1223/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5092 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01223: mean_squared_error improved from 0.00708 to 0.00698, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1224/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9653 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01224: mean_squared_error did not improve from 0.00698\n",
      "Epoch 1225/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7659 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01225: mean_squared_error did not improve from 0.00698\n",
      "Epoch 1226/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6436 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01226: mean_squared_error did not improve from 0.00698\n",
      "Epoch 1227/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4939 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01227: mean_squared_error improved from 0.00698 to 0.00694, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1228/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6630 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01228: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1229/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5344 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01229: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1230/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5002 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01230: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1231/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.7263 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01231: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1232/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8442 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01232: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1233/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4698 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01233: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1234/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.2164 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 01234: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1235/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5565 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01235: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1236/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5416 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01236: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1237/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6501 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01237: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1238/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0289 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 01238: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1239/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6524 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01239: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1240/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3674 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01240: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1241/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4130 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01241: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1242/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3677 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01242: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1243/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3332 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01243: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1244/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6111 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01244: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1245/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5260 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01245: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1246/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4102 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01246: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1247/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3092 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01247: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1248/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3130 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01248: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1249/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3549 - mean_squared_error: 0.0114\n",
      "\n",
      "Epoch 01249: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1250/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3611 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01250: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1251/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6332 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01251: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1252/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5665 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01252: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1253/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7485 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01253: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1254/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5155 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01254: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1255/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8898 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01255: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1256/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3048 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01256: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1257/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9068 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01257: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1258/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4053 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01258: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1259/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6998 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01259: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1260/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6831 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01260: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1261/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5791 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01261: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1262/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5106 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01262: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1263/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4841 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01263: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1264/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5253 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01264: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1265/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7115 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01265: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1266/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4596 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01266: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1267/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1764 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 01267: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1268/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9376 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01268: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1269/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6176 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01269: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1270/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8388 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01270: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1271/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7216 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01271: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1272/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1596 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 01272: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1273/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4845 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01273: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1274/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6309 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01274: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1275/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6954 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01275: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1276/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3184 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01276: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1277/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6946 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01277: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1278/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4385 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01278: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1279/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.8299 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01279: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1280/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6899 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01280: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1281/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3285 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01281: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1282/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5329 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01282: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1283/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6166 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01283: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1284/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6419 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01284: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1285/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6912 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01285: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1286/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3879 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01286: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1287/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1331 - mean_squared_error: 0.0103\n",
      "\n",
      "Epoch 01287: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1288/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4086 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01288: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1289/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6804 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01289: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1290/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6784 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01290: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1291/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7769 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01291: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1292/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5226 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01292: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1293/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6295 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01293: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1294/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.0134 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01294: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1295/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7311 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01295: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1296/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6498 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01296: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1297/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3150 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01297: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1298/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1078 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 01298: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1299/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5857 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01299: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1300/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9178 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01300: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1301/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4974 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01301: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1302/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4132 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01302: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1303/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4064 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01303: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1304/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5901 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01304: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1305/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9057 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01305: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1306/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4758 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01306: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1307/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6696 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01307: mean_squared_error did not improve from 0.00694\n",
      "Epoch 1308/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2219 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01308: mean_squared_error improved from 0.00694 to 0.00687, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1309/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4612 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01309: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1310/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3296 - mean_squared_error: 0.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01310: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1311/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5560 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01311: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1312/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.7185 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01312: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1313/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.6654 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01313: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1314/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.5010 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01314: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1315/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.9175 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01315: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1316/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.6147 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01316: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1317/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3374 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01317: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1318/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.8204 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01318: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1319/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8087 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01319: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1320/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.4431 - mean_squared_error: 0.0112\n",
      "\n",
      "Epoch 01320: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1321/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4433 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01321: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1322/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.6593 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01322: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1323/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.7111 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01323: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1324/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.7851 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01324: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1325/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.6868 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01325: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1326/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.5346 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01326: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1327/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4996 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01327: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1328/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6025 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01328: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1329/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6255 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01329: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1330/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6032 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01330: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1331/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5047 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01331: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1332/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3985 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01332: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1333/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3414 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01333: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1334/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4027 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01334: mean_squared_error did not improve from 0.00687\n",
      "Epoch 1335/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1752 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01335: mean_squared_error improved from 0.00687 to 0.00670, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1336/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6578 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01336: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1337/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2727 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01337: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1338/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.6649 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01338: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1339/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.9918 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 01339: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1340/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5727 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01340: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1341/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5666 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01341: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1342/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4501 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01342: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1343/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6259 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01343: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1344/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5394 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01344: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1345/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4717 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01345: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1346/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 6.0906 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 01346: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1347/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7308 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01347: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1348/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4667 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01348: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1349/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5124 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01349: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1350/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7136 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01350: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1351/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4777 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01351: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1352/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.4078 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01352: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1353/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6596 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01353: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1354/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2521 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01354: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1355/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5312 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01355: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1356/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4337 - mean_squared_error: 0.0079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01356: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1357/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 6.6277 - mean_squared_error: 0.0121\n",
      "\n",
      "Epoch 01357: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1358/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.8323 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01358: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1359/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.4059 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01359: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1360/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.4004 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01360: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1361/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.5352 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01361: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1362/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4396 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01362: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1363/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.3341 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01363: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1364/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.3773 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01364: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1365/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.5543 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01365: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1366/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.4605 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01366: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1367/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4143 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01367: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1368/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.5809 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01368: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1369/2000\n",
      "28/28 [==============================] - 1s 22ms/step - loss: 5.9495 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 01369: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1370/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.7191 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01370: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1371/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.3659 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01371: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1372/2000\n",
      "28/28 [==============================] - 1s 21ms/step - loss: 5.8117 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01372: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1373/2000\n",
      "28/28 [==============================] - 1s 19ms/step - loss: 5.3063 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01373: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1374/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.6051 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01374: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1375/2000\n",
      "28/28 [==============================] - 1s 23ms/step - loss: 5.7748 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01375: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1376/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.5908 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01376: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1377/2000\n",
      "28/28 [==============================] - 1s 24ms/step - loss: 5.5622 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01377: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1378/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.5571 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01378: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1379/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.4453 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01379: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1380/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.2160 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01380: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1381/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.3774 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01381: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1382/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.7377 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01382: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1383/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3170 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01383: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1384/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9360 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 01384: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1385/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2490 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01385: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1386/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4528 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01386: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1387/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5290 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01387: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1388/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2488 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01388: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1389/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7196 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01389: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1390/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4056 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01390: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1391/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2119 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01391: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1392/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4152 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01392: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1393/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.3103 - mean_squared_error: 0.0111\n",
      "\n",
      "Epoch 01393: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1394/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5915 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01394: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1395/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6471 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01395: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1396/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4181 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01396: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1397/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6405 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01397: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1398/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7825 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01398: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1399/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5764 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01399: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1400/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8612 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01400: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1401/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6134 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01401: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1402/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5658 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01402: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1403/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7890 - mean_squared_error: 0.0086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01403: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1404/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4267 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01404: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1405/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2870 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01405: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1406/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7540 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01406: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1407/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7512 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01407: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1408/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4102 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01408: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1409/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4680 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01409: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1410/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3893 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01410: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1411/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3734 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01411: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1412/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4592 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01412: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1413/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3718 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01413: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1414/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4188 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01414: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1415/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5537 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01415: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1416/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3147 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01416: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1417/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 6.1612 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01417: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1418/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7473 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01418: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1419/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.9639 - mean_squared_error: 0.0100\n",
      "\n",
      "Epoch 01419: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1420/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4705 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01420: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1421/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4503 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01421: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1422/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4848 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01422: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1423/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3992 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01423: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1424/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3698 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01424: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1425/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5096 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01425: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1426/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3255 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01426: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1427/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6723 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01427: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1428/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3779 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01428: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1429/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6195 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01429: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1430/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4671 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01430: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1431/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3641 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01431: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1432/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7912 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01432: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1433/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3189 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01433: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1434/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6288 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01434: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1435/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4051 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01435: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1436/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3538 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01436: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1437/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4180 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01437: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1438/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4363 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01438: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1439/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4113 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01439: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1440/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4769 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01440: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1441/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6226 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01441: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1442/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1681 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01442: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1443/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.4292 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01443: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1444/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2106 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01444: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1445/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3089 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01445: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1446/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3746 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01446: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1447/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.5469 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01447: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1448/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3690 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01448: mean_squared_error did not improve from 0.00670\n",
      "Epoch 1449/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9873 - mean_squared_error: 0.0066\n",
      "\n",
      "Epoch 01449: mean_squared_error improved from 0.00670 to 0.00659, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1450/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1899 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01450: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1451/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.5440 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01451: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1452/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5087 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01452: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1453/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2429 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01453: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1454/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7902 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01454: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1455/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5716 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01455: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1456/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3984 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01456: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1457/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3552 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01457: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1458/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.5224 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01458: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1459/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3498 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01459: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1460/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3392 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01460: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1461/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3840 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01461: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1462/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3492 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01462: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1463/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4280 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01463: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1464/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1923 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01464: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1465/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5915 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01465: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1466/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.1449 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01466: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1467/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.6363 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01467: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1468/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.2169 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01468: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1469/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.4236 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01469: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1470/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6154 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01470: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1471/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1940 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01471: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1472/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.5766 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01472: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1473/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3100 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01473: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1474/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4976 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01474: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1475/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3767 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01475: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1476/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2810 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01476: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1477/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3751 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01477: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1478/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.6813 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01478: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1479/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5101 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01479: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1480/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5519 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01480: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1481/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5210 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01481: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1482/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7265 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01482: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1483/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.6104 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01483: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1484/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4965 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01484: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1485/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4480 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01485: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1486/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4438 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01486: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1487/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.5691 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01487: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1488/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4264 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01488: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1489/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7244 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01489: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1490/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3333 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01490: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1491/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1401 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01491: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1492/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3453 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01492: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1493/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2513 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01493: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1494/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.1945 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01494: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1495/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.0155 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01495: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1496/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1340 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01496: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1497/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3506 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01497: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1498/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0191 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01498: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1499/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.3591 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01499: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1500/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1923 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01500: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1501/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1673 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01501: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1502/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1239 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01502: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1503/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6171 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01503: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1504/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2921 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01504: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1505/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1898 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01505: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1506/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2340 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01506: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1507/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.5992 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01507: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1508/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3548 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01508: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1509/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1334 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01509: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1510/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7730 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 01510: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1511/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.6427 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01511: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1512/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2434 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01512: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1513/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6221 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01513: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1514/2000\n",
      "28/28 [==============================] - 1s 18ms/step - loss: 5.2662 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01514: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1515/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3154 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01515: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1516/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4010 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01516: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1517/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1404 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01517: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1518/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.3720 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01518: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1519/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.6818 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01519: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1520/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2262 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01520: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1521/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.7062 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01521: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1522/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.4332 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01522: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1523/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.1707 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01523: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1524/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 5.2237 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01524: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1525/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.4522 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01525: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1526/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.2493 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01526: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1527/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.0996 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01527: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1528/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3512 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01528: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1529/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 6.7476 - mean_squared_error: 0.0130\n",
      "\n",
      "Epoch 01529: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1530/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1757 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01530: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1531/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.6101 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01531: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1532/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.4892 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01532: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1533/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 5.3320 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01533: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1534/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.1883 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01534: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1535/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3810 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01535: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1536/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.1587 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01536: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1537/2000\n",
      "28/28 [==============================] - 0s 18ms/step - loss: 5.5449 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01537: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1538/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 6.0703 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01538: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1539/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4147 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01539: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1540/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3163 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01540: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1541/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.5581 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01541: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1542/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3572 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01542: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1543/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2229 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01543: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1544/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 12ms/step - loss: 5.2037 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01544: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1545/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.2418 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01545: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1546/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3131 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01546: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1547/2000\n",
      "28/28 [==============================] - 0s 17ms/step - loss: 5.4887 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01547: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1548/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4358 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01548: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1549/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2474 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01549: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1550/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5724 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01550: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1551/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2165 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01551: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1552/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.1386 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01552: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1553/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2591 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01553: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1554/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2289 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01554: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1555/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0973 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01555: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1556/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2789 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01556: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1557/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.9271 - mean_squared_error: 0.0099\n",
      "\n",
      "Epoch 01557: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1558/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6044 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01558: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1559/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1395 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01559: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1560/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.2204 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01560: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1561/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.8719 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01561: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1562/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2332 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01562: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1563/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.2372 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01563: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1564/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.5794 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01564: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1565/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1095 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01565: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1566/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4813 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01566: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1567/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1727 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01567: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1568/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.1973 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01568: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1569/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3123 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01569: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1570/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.6076 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01570: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1571/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3962 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01571: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1572/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2592 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01572: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1573/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0202 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01573: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1574/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 6.0683 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 01574: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1575/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1886 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01575: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1576/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4054 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01576: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1577/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4044 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01577: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1578/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.2353 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01578: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1579/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.2455 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01579: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1580/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2262 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01580: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1581/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2129 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01581: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1582/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2643 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01582: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1583/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1586 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01583: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1584/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.6944 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01584: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1585/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3089 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01585: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1586/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0827 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01586: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1587/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1377 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01587: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1588/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0720 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01588: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1589/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0835 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01589: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1590/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3521 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01590: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1591/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4110 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01591: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1592/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1514 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01592: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1593/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1509 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01593: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1594/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.8562 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 01594: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1595/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4121 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01595: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1596/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3060 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01596: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1597/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.3996 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01597: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1598/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.5373 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01598: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1599/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3242 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01599: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1600/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4326 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01600: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1601/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2634 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01601: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1602/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3155 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01602: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1603/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4654 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01603: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1604/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3875 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01604: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1605/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4055 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01605: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1606/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2981 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01606: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1607/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.0407 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01607: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1608/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4093 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01608: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1609/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4570 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01609: mean_squared_error did not improve from 0.00659\n",
      "Epoch 1610/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9325 - mean_squared_error: 0.0065\n",
      "\n",
      "Epoch 01610: mean_squared_error improved from 0.00659 to 0.00654, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1611/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1832 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01611: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1612/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.1399 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01612: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1613/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1356 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01613: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1614/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1019 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01614: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1615/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0606 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01615: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1616/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0307 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01616: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1617/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3072 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01617: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1618/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.6499 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 01618: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1619/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0650 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01619: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1620/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3787 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01620: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1621/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9830 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01621: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1622/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9589 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01622: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1623/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.2377 - mean_squared_error: 0.0116\n",
      "\n",
      "Epoch 01623: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1624/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2543 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01624: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1625/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0891 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01625: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1626/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2432 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01626: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1627/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2145 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01627: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1628/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5355 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01628: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1629/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2634 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01629: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1630/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0766 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01630: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1631/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3863 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01631: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1632/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2395 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01632: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1633/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1569 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01633: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1634/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1906 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01634: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1635/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1176 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01635: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1636/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.2052 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01636: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1637/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3389 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01637: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1638/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.7202 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01638: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1639/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2627 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01639: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1640/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5338 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01640: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1641/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2786 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01641: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1642/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3465 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01642: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1643/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1839 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01643: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1644/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0114 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01644: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1645/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1757 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01645: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1646/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 6.0299 - mean_squared_error: 0.0105\n",
      "\n",
      "Epoch 01646: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1647/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2226 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01647: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1648/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3477 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01648: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1649/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2454 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01649: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1650/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.3122 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01650: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1651/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3860 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01651: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1652/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3717 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01652: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1653/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3610 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01653: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1654/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.8291 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01654: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1655/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1319 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01655: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1656/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2247 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01656: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1657/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1845 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01657: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1658/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.6455 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01658: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1659/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9620 - mean_squared_error: 0.0066\n",
      "\n",
      "Epoch 01659: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1660/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1044 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01660: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1661/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3171 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01661: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1662/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2670 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01662: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1663/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.9965 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01663: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1664/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0264 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01664: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1665/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3030 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01665: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1666/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.2961 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01666: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1667/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.0772 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01667: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1668/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.2742 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01668: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1669/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.0743 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01669: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1670/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.1635 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01670: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1671/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0851 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01671: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1672/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9925 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01672: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1673/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1454 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01673: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1674/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.6608 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 01674: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1675/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1560 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01675: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1676/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2732 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01676: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1677/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1377 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01677: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1678/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9888 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01678: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1679/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9529 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01679: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1680/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0422 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01680: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1681/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9131 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01681: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1682/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9741 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01682: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1683/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9299 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01683: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1684/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1759 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01684: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1685/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.4823 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01685: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1686/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.8609 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 01686: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1687/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.6635 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 01687: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1688/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9710 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01688: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1689/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0124 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01689: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1690/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0795 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01690: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1691/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1390 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01691: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1692/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0940 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01692: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1693/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3873 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01693: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1694/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0570 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01694: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1695/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.5945 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01695: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1696/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4516 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01696: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1697/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1129 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01697: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1698/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.2868 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01698: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1699/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1085 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01699: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1700/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3144 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01700: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1701/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2399 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01701: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1702/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1814 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01702: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1703/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1304 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01703: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1704/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0218 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01704: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1705/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.5232 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01705: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1706/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3210 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01706: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1707/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2127 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01707: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1708/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9787 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01708: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1709/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0958 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01709: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1710/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1350 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01710: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1711/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2390 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01711: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1712/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2365 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01712: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1713/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1587 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01713: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1714/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1051 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01714: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1715/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0386 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01715: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1716/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2600 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01716: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1717/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1074 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01717: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1718/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0757 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01718: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1719/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1232 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01719: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1720/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0283 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01720: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1721/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1416 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01721: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1722/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1471 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01722: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1723/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.7681 - mean_squared_error: 0.0066\n",
      "\n",
      "Epoch 01723: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1724/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2629 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01724: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1725/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1236 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01725: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1726/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2865 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01726: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1727/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9657 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01727: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1728/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1474 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01728: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1729/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2619 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01729: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1730/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8603 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01730: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1731/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0845 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01731: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1732/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0227 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01732: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1733/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9467 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01733: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1734/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0672 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01734: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1735/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9241 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01735: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1736/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3731 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01736: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1737/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3306 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01737: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1738/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9085 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01738: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1739/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9391 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01739: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1740/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.7658 - mean_squared_error: 0.0102\n",
      "\n",
      "Epoch 01740: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1741/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0148 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01741: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1742/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1913 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01742: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1743/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3480 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01743: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1744/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8657 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01744: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1745/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3311 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01745: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1746/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1302 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01746: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1747/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8422 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01747: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1748/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1721 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01748: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1749/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0632 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01749: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1750/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0265 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01750: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1751/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0477 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01751: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1752/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0924 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01752: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1753/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.8708 - mean_squared_error: 0.0141\n",
      "\n",
      "Epoch 01753: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1754/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4916 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01754: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1755/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1781 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01755: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1756/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.7188 - mean_squared_error: 0.0097\n",
      "\n",
      "Epoch 01756: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1757/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2361 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01757: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1758/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3037 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01758: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1759/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0509 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01759: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1760/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2142 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01760: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1761/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1374 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01761: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1762/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1519 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01762: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1763/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.9587 - mean_squared_error: 0.0066\n",
      "\n",
      "Epoch 01763: mean_squared_error did not improve from 0.00654\n",
      "Epoch 1764/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8786 - mean_squared_error: 0.0064\n",
      "\n",
      "Epoch 01764: mean_squared_error improved from 0.00654 to 0.00641, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1765/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2436 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01765: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1766/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3306 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01766: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1767/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2966 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01767: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1768/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1610 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01768: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1769/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3405 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01769: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1770/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.9935 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01770: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1771/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 4.9073 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01771: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1772/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.9251 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01772: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1773/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.1986 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01773: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1774/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.8711 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01774: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1775/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3982 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01775: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1776/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.1599 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01776: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 13ms/step - loss: 5.5834 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01777: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1778/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2792 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01778: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1779/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0799 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01779: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1780/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3282 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01780: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1781/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.8924 - mean_squared_error: 0.0106\n",
      "\n",
      "Epoch 01781: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1782/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0072 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01782: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1783/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4880 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01783: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1784/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1686 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01784: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1785/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0309 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01785: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1786/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1378 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01786: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1787/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5894 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01787: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1788/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2840 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01788: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1789/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.2118 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01789: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1790/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1576 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01790: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1791/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.2238 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01791: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1792/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0877 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01792: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1793/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9868 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01793: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1794/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0698 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01794: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1795/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2377 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01795: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1796/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2211 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01796: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1797/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0031 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01797: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1798/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8737 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01798: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1799/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1820 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01799: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1800/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8904 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01800: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1801/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8059 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01801: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1802/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0397 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01802: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1803/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5543 - mean_squared_error: 0.0095\n",
      "\n",
      "Epoch 01803: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1804/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2894 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01804: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1805/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.7733 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01805: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1806/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1697 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01806: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1807/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0705 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01807: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1808/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.3826 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01808: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1809/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.8489 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01809: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1810/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1056 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01810: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1811/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9895 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01811: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1812/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2933 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01812: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1813/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1914 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01813: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1814/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8512 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01814: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1815/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2386 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01815: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1816/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4264 - mean_squared_error: 0.0088\n",
      "\n",
      "Epoch 01816: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1817/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0204 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01817: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1818/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0930 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01818: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1819/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2817 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01819: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1820/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9318 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01820: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1821/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8667 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01821: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1822/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9093 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01822: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1823/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4040 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01823: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1824/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2366 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01824: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1825/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1323 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01825: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1826/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0453 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01826: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1827/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2936 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01827: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1828/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4162 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01828: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1829/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.9240 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01829: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1830/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9199 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01830: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1831/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4515 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01831: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1832/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3678 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01832: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1833/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9080 - mean_squared_error: 0.0065\n",
      "\n",
      "Epoch 01833: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1834/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9721 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01834: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1835/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1946 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01835: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1836/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9612 - mean_squared_error: 0.0066\n",
      "\n",
      "Epoch 01836: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1837/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0032 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01837: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1838/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9902 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01838: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1839/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0105 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01839: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1840/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9850 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01840: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1841/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1452 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01841: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1842/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9826 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01842: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1843/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.7320 - mean_squared_error: 0.0096\n",
      "\n",
      "Epoch 01843: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1844/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8369 - mean_squared_error: 0.0065\n",
      "\n",
      "Epoch 01844: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1845/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.9625 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01845: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1846/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.0907 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01846: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1847/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9144 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01847: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1848/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3985 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01848: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1849/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1221 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01849: mean_squared_error did not improve from 0.00641\n",
      "Epoch 1850/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.6816 - mean_squared_error: 0.0062\n",
      "\n",
      "Epoch 01850: mean_squared_error improved from 0.00641 to 0.00624, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1851/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.6637 - mean_squared_error: 0.0062\n",
      "\n",
      "Epoch 01851: mean_squared_error improved from 0.00624 to 0.00623, saving model to /Users/francesco/github/LASTS/trained_models/coffee/weights/autoencoders/20200724_133050/vae_best_weights.hdf5\n",
      "Epoch 1852/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8739 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01852: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1853/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1080 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01853: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1854/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8664 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01854: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1855/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0079 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01855: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1856/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8497 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01856: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1857/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1776 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01857: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1858/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.6694 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01858: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1859/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9075 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01859: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1860/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1275 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01860: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1861/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2477 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01861: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1862/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.3365 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01862: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1863/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.6920 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01863: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1864/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3085 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01864: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1865/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0107 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01865: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1866/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9371 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01866: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1867/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9943 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01867: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1868/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4749 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01868: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1869/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9964 - mean_squared_error: 0.0075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01869: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1870/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1074 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01870: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1871/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.4488 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01871: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1872/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.7805 - mean_squared_error: 0.0065\n",
      "\n",
      "Epoch 01872: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1873/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8820 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01873: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1874/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1330 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01874: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1875/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2629 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01875: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1876/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9555 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01876: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1877/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.9003 - mean_squared_error: 0.0104\n",
      "\n",
      "Epoch 01877: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1878/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8974 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01878: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1879/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1094 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01879: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1880/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2306 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01880: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1881/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.9516 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01881: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1882/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1849 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01882: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1883/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0687 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01883: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1884/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0408 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01884: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1885/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1539 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01885: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1886/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.0820 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01886: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1887/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1025 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01887: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1888/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.4728 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01888: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1889/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9472 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01889: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1890/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0902 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01890: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1891/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.5741 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01891: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1892/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2829 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01892: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1893/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9345 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01893: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1894/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 4.9814 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01894: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1895/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.8287 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01895: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1896/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0728 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01896: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1897/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 6.0811 - mean_squared_error: 0.0113\n",
      "\n",
      "Epoch 01897: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1898/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.9932 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01898: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1899/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8465 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01899: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1900/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1908 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01900: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1901/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9648 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01901: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1902/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.0896 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01902: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1903/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9442 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01903: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1904/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.8065 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01904: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1905/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1248 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01905: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1906/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.9141 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01906: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1907/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.9939 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01907: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1908/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 5.1199 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01908: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1909/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 4.6991 - mean_squared_error: 0.0065\n",
      "\n",
      "Epoch 01909: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1910/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.7759 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01910: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1911/2000\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 4.9175 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01911: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1912/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.0112 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01912: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1913/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8499 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01913: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1914/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.7987 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01914: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1915/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.5987 - mean_squared_error: 0.0064\n",
      "\n",
      "Epoch 01915: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1916/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.9498 - mean_squared_error: 0.0077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01916: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1917/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.1392 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01917: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1918/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.8396 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01918: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1919/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0954 - mean_squared_error: 0.0082\n",
      "\n",
      "Epoch 01919: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1920/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8799 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01920: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1921/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0303 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01921: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1922/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9437 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01922: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1923/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9905 - mean_squared_error: 0.0078\n",
      "\n",
      "Epoch 01923: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1924/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9502 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01924: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1925/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.7377 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01925: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1926/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.3876 - mean_squared_error: 0.0092\n",
      "\n",
      "Epoch 01926: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1927/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9029 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01927: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1928/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 5.8900 - mean_squared_error: 0.0109\n",
      "\n",
      "Epoch 01928: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1929/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8036 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01929: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1930/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3563 - mean_squared_error: 0.0089\n",
      "\n",
      "Epoch 01930: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1931/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0166 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01931: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1932/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9652 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01932: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1933/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4488 - mean_squared_error: 0.0090\n",
      "\n",
      "Epoch 01933: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1934/2000\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 4.8946 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01934: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1935/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.5617 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01935: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1936/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9439 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01936: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1937/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1154 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01937: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1938/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1083 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01938: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1939/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0136 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01939: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1940/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.1023 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01940: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1941/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.2094 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01941: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1942/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.0552 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01942: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1943/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8764 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01943: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1944/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9483 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01944: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1945/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9537 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01945: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1946/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8829 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01946: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1947/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.6761 - mean_squared_error: 0.0063\n",
      "\n",
      "Epoch 01947: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1948/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9714 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01948: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1949/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2241 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01949: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1950/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9144 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01950: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1951/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8980 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01951: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1952/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8884 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01952: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1953/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8161 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01953: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1954/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8109 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01954: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1955/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.7159 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01955: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1956/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1044 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01956: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1957/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3687 - mean_squared_error: 0.0093\n",
      "\n",
      "Epoch 01957: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1958/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9008 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01958: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1959/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8064 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01959: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1960/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.1439 - mean_squared_error: 0.0086\n",
      "\n",
      "Epoch 01960: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1961/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.3047 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01961: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1962/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.7680 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01962: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1963/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.6907 - mean_squared_error: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01963: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1964/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.6006 - mean_squared_error: 0.0066\n",
      "\n",
      "Epoch 01964: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1965/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.3294 - mean_squared_error: 0.0091\n",
      "\n",
      "Epoch 01965: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1966/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0005 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01966: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1967/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8318 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01967: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1968/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 5.0810 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01968: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1969/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 4.9783 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01969: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1970/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 5.1158 - mean_squared_error: 0.0084\n",
      "\n",
      "Epoch 01970: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1971/2000\n",
      "28/28 [==============================] - 0s 16ms/step - loss: 4.6910 - mean_squared_error: 0.0069\n",
      "\n",
      "Epoch 01971: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1972/2000\n",
      "28/28 [==============================] - 0s 15ms/step - loss: 5.0554 - mean_squared_error: 0.0081\n",
      "\n",
      "Epoch 01972: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1973/2000\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 5.5505 - mean_squared_error: 0.0098\n",
      "\n",
      "Epoch 01973: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1974/2000\n",
      "28/28 [==============================] - 0s 14ms/step - loss: 4.8451 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01974: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1975/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8879 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01975: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1976/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9297 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01976: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1977/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8868 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01977: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1978/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8431 - mean_squared_error: 0.0071\n",
      "\n",
      "Epoch 01978: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1979/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.4650 - mean_squared_error: 0.0094\n",
      "\n",
      "Epoch 01979: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1980/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9120 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01980: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1981/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8431 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01981: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1982/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.0644 - mean_squared_error: 0.0079\n",
      "\n",
      "Epoch 01982: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1983/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1490 - mean_squared_error: 0.0083\n",
      "\n",
      "Epoch 01983: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1984/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.9262 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01984: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1985/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.2853 - mean_squared_error: 0.0087\n",
      "\n",
      "Epoch 01985: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1986/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.6383 - mean_squared_error: 0.0065\n",
      "\n",
      "Epoch 01986: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1987/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.7824 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 01987: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1988/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9781 - mean_squared_error: 0.0077\n",
      "\n",
      "Epoch 01988: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1989/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.8424 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01989: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1990/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.2101 - mean_squared_error: 0.0085\n",
      "\n",
      "Epoch 01990: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1991/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 5.6517 - mean_squared_error: 0.0101\n",
      "\n",
      "Epoch 01991: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1992/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.8722 - mean_squared_error: 0.0073\n",
      "\n",
      "Epoch 01992: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1993/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.7585 - mean_squared_error: 0.0068\n",
      "\n",
      "Epoch 01993: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1994/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.8796 - mean_squared_error: 0.0072\n",
      "\n",
      "Epoch 01994: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1995/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 4.9549 - mean_squared_error: 0.0074\n",
      "\n",
      "Epoch 01995: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1996/2000\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 5.1316 - mean_squared_error: 0.0080\n",
      "\n",
      "Epoch 01996: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1997/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.7515 - mean_squared_error: 0.0067\n",
      "\n",
      "Epoch 01997: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1998/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9880 - mean_squared_error: 0.0076\n",
      "\n",
      "Epoch 01998: mean_squared_error did not improve from 0.00623\n",
      "Epoch 1999/2000\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 4.9666 - mean_squared_error: 0.0075\n",
      "\n",
      "Epoch 01999: mean_squared_error did not improve from 0.00623\n",
      "Epoch 2000/2000\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 4.7972 - mean_squared_error: 0.0070\n",
      "\n",
      "Epoch 02000: mean_squared_error did not improve from 0.00623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a76d4afd0>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#batch_size = 40\n",
    "epochs=2000\n",
    "autoencoder.fit(\n",
    "    X_exp_train, \n",
    "    X_exp_train, \n",
    "    epochs=epochs, \n",
    "    #validation_data=(X_exp_val, X_exp_val), \n",
    "    #batch_size=batch_size,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-1dba3ec82def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/LASTS/variational_autoencoder.py\u001b[0m in \u001b[0;36mplot_history\u001b[0;34m(history_dict)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LOSS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_loss'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(autoencoder.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.load_weights(parentdir + \"/trained_models/coffee/weights/autoencoders/\" + \"20200724_133050\" + \"/vae_best_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7142857142857143 ± 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_accuracy(X_exp_test, encoder, decoder, blackbox, repeat=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9178571428571429 ± 0.02789374884252375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9178571428571429"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction_accuracy_vae(X_exp_test, encoder, decoder, blackbox, repeat=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import reconstruction_accuracy_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_reconstruction_vae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from variational_autoencoder import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(autoencoder, input_shape, latent_dim, autoencoder_kwargs, \n",
    "           path=parentdir + \"/trained_models/coffee/weights/autoencoders/\" + \"20200723_181036\" + \"/coffee_vae\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_reconstruction_vae(X_exp_train[:5], encoder, decoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
